searchState.loadedDescShard("polars_lazy", 0, "Lazy API of Polars\nDomain specific language for the Lazy API.\nHelper to delay a failing method until the query plan is …\nLazy variant of a DataFrame.\nSpecialized expressions for <code>Series</code> of <code>DataType::Array</code>.\nSpecialized expressions for Categorical dtypes.\nUtility struct for the <code>when-then-otherwise</code> expression.\nUtility struct for the <code>when-then-otherwise</code> expression.\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nCan be used in a select statement to exclude a column from …\nExplode the aggregated list and just do a hstack instead …\nExpressions that can be used in various contexts. Queries …\nSpecialized expressions for modifying the name of existing …\nMap the group values to the position\nJoin the groups as ‘List&lt;group_dtype&gt;’ to the row …\nSet root name as Alias\nSpecialized expressions for <code>Series</code> of <code>DataType::List</code>.\nSpecialized expressions for Categorical dtypes.\nTake the nth column in the <code>DataFrame</code>\nExplode the aggregated list and just do a hstack instead …\nExpressions in this node should only be expanding e.g. …\nA wrapper trait for any binary closure …\nA wrapper trait for any closure …\nWrapper type that has special equality properties …\nSpecialized expressions for Struct dtypes.\nA ternary operation if true then “foo” else “bar”\nUtility struct for the <code>when-then-otherwise</code> expression.\nRepresents a user-defined function\nUtility struct for the <code>when-then-otherwise</code> expression.\nPolars flavored window functions.\nConvert all values to their absolute/positive value.\nGet the group indexes of the group by operation.\nRename Column.\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nEvaluate whether all boolean values are true for every …\nReturns whether all values in the column are <code>true</code>.\nCreate a new column with the bitwise-and of the elements …\n“and” operation.\nEvaluate whether any boolean value is true for every …\nReturns whether any of the values in the column are <code>true</code>.\nCreate a new column with the bitwise-or of the elements in …\nAppend expressions. This is done by adding the chunks of …\nApply a function/closure over the groups. This should only …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nApply a function/closure over the groups with many …\nApply a function/closure over the groups of multiple …\nGet the approximate count of unique values.\nGenerate a range of integers.\nCompute the inverse cosine of the given expression\nCompute the inverse hyperbolic cosine of the given …\nCompute the inverse sine of the given expression\nCompute the inverse hyperbolic sine of the given expression\nCompute the inverse tangent of the given expression\nCompute the inverse tangent of the given expression, with …\nCompute the inverse hyperbolic tangent of the given …\nReturn the index of the maximum value of every sublist\nGet the index value that has the maximum value.\nReturn the index of the minimal value of every sublist\nGet the index value that has the minimum value.\nGet the index values that would sort this expression.\nFind the indexes that would sort these series in order of …\nGet the first index of unique values of this expression.\nGet the indices where <code>condition</code> evaluates <code>true</code>.\nGet the <code>array::ArrayNameSpace</code>.\nTake several expressions and collect them into a …\nFind the mean of all the values in the column named <code>name</code>. …\nFill missing value with next non-null.\nGet the <code>binary::BinaryNameSpace</code>\nCompute <code>op(l, r)</code> (or equivalently <code>l op r</code>). <code>l</code> and <code>r</code> must …\nReturns the <code>k</code> smallest elements.\nReturns the <code>k</code> smallest rows by given column.\nuse a cache of unique, converted dates to apply the …\ncreates a logical expression with a call of the UDF This …\ncreates a logical expression with a call of the UDF This …\nCasts the column given by <code>Expr</code> to a different type.\nCast expression to another data type.\nCast expression to another data type.\nGet the <code>CategoricalNameSpace</code>.\nCompute the cube root of the given expression\nCeil underlying floating point array to the highest …\nClip underlying values to a set boundary.\nClip underlying values to a set boundary.\nClip underlying values to a set boundary.\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nSelect multiple columns by name.\nConcat lists entries.\nHorizontally concat string columns in linear time\nCheck if the sub-array contains specific element\nCheck if the list array contain an element\nCompute the cosine of the given expression\nCompute the hyperbolic cosine of the given expression\nCompute the cotangent of the given expression\nCount the values of the Series or Get counts of the group …\nCount how often the value produced by <code>element</code> occurs.\nCount how often the value produced by <code>element</code> occurs.\nCompute the covariance between two columns.\nCumulatively count values from 0 to len.\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative max computed at every …\nGet an array with the cumulative min computed at every …\nGet an array with the cumulative product computed at every …\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative sum computed at every …\nRun an expression over a sliding window that increases <code>1</code> …\nRun an expression over a sliding window that increases <code>1</code> …\nBin continuous values into discrete categories.\nCreate a column of date ranges from a <code>start</code> and <code>stop</code> …\nConstruct a column of <code>Datetime</code> from the provided …\nCreate a datetime range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of datetime ranges from a <code>start</code> and <code>stop</code> …\nConvert from radians to degrees\nDiff every sublist.\nCalculate the n-th discrete difference between values.\nCompute the dot/inner product between two expressions.\nDrop NaN values.\nDrop null values.\nGet the <code>dt::DateLikeNameSpace</code>\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nCompute the entropy as <code>-sum(pk * log(pk)</code>. where <code>pk</code> are …\nCompare <code>Expr</code> with other <code>Expr</code> on equality.\nCompare <code>Expr</code> with other <code>Expr</code> on equality where <code>None == None</code>…\nRun any <code>Expr</code> on these lists elements\nRun any <code>Expr</code> on these lists elements\nCalculate the exponentially-weighted moving average.\nCalculate the exponentially-weighted moving average by a …\nCalculate the exponentially-weighted moving standard …\nCalculate the exponentially-weighted moving variance.\nIf polars may parse matches that not contain the whole …\nExclude a column from a wildcard/regex selection.\nCalculate the exponential of all elements in the input …\nExplode the String/List column.\nRetrieve one of the fields of this <code>StructChunked</code> as a new …\nRetrieve one or multiple of the fields of this …\nReplace the floating point <code>NaN</code> values by a value.\nReplace the null values by a value.\nFilter a single column.\nFirst column in a DataFrame.\nGet first item of every sublist.\nGet the first value in the group.\nAlias for <code>explode</code>.\nFloor underlying floating point array to the lowest …\nFloor divide <code>self</code> by <code>rhs</code>.\nAccumulate over multiple columns horizontally / row wise.\nFormatting string\nFormat the results of an array of expressions using a …\nFill missing value with previous non-null.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe function implementation.\nA function that cannot be expressed with <code>map</code> or <code>apply</code> and …\nFunctions\nGet items in every sublist by multiple indexes.\nTake the values by idx.\nGet items in every sub-array by index.\nGet items in every sublist by index.\nTake the values by a single index.\nCheck if <code>Expr</code> &gt; <code>Expr</code>.\nCheck if <code>Expr</code> &gt;= <code>Expr</code>.\nIndicate if this expression expands to multiple …\nCompute the hash of every element.\nGet the head of every sublist\nGet the first <code>n</code> elements of the Expr result.\nCompute the histogram of a dataset.\nGroupBy the group to a Series.\nSelect multiple columns by index.\nThe function signature.\nGenerate a range of integers.\nGenerate a range of integers for each row of the input …\nFill null values using interpolation.\nFill null values using interpolation.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet a hold to an implementor of the <code>Display</code> trait that …\nIndicate if this expression is a basic (non-regex) column.\nIndicate if this expression only selects columns; the …\nGet a mask of duplicated values.\nGet mask of finite values if dtype is Float.\nGet a mask of the first unique value.\nCheck if the values of the left expression are in the …\nGet mask of infinite values if dtype is Float.\nGet a mask of the last unique value.\nGet mask of NaN values if dtype is Float.\nGet inverse mask of NaN values if dtype is Float.\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nRun is_not_null operation on <code>Expr</code>.\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nRun is_null operation on <code>Expr</code>.\nIndicate if this expression expands to multiple …\nA projection that only takes a column or a column + alias.\nGet a mask of unique values.\nJoin all string items in a sub-array and place a separator …\nJoin all string items in a sublist and place a separator …\nKeep the original root name\nCompute the kurtosis (Fisher or Pearson).\nLast column in a DataFrame.\nGet last item of every sublist.\nGet the last value in the group.\nReturn the number of rows in the context.\nReturn the number of elements in each list.\nGet the <code>list::ListNameSpace</code>\nCreate a Literal Expression from <code>L</code>. A literal expression …\nCompute the logarithm to a given base.\nCompute the natural logarithm of all elements plus one in …\n“or” operation.\n“or” operation.\nGet minimal value that could be hold by this dtype.\nCheck if <code>Expr</code> &lt; <code>Expr</code>.\nCheck if <code>Expr</code> &lt;= <code>Expr</code>.\nDefine an alias by mapping a function over the original …\nApply a function/closure once the logical plan get …\nApply a closure on the two columns that are evaluated from …\nSet the timezone of a datetime dtype.\nMap a single dtype.\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nMap to a float supertype if numeric, else preserve\nMap to a float supertype.\nMap the dtype to the dtype of the list/array elements.\nMap the dtypes to the “supertype” of a list of lists.\nMap the dtype to the “supertype” of all fields.\nFind the maximum of all the values in the column named <code>name</code>…\nCompute the maximum of the items in every subarray.\nCompute the maximum of the items in every sublist.\nReduce groups to maximum value.\nCreate a new column with the maximum value per row.\nFind the mean of all the values in the column named <code>name</code>. …\nCompute the mean of every sublist and return a <code>Series</code> of …\nReduce groups to the mean value.\nCompute the mean of all values horizontally across columns.\nFind the median of all the values in the column named <code>name</code>…\nCompute the median of the items in every subarray.\nReduce groups to the median value.\nGet the <code>meta::MetaNameSpace</code>\nFind the minimum of all the values in the column named <code>name</code>…\nCompute the minimum of the items in every subarray.\nCompute the minimum of the items in every sublist.\nReduce groups to minimal value.\nCreate a new column with the minimum value per row.\nCompute the mode(s) of this column. This is the most …\nGet the number of unique values in the groups.\nGet the <code>name::ExprNameNameSpace</code>\nname\nReduce groups to maximum value.\nReduce groups to minimal value.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality where …\nConstruct a new <code>DatetimeArgs</code> set to <code>year</code>, <code>month</code>, <code>day</code>\nCreate a new <code>DurationArgs</code> with all fields set to <code>lit(0)</code>. …\nCreate a new UserDefinedFunction\nNegates a boolean column.\nNegate <code>Expr</code>.\nNth column in a DataFrame.\nGet the null count of the column/group.\nOptions for the function.\n“or” operation.\nDefine a default for the <code>when-then-otherwise</code> expression.\nDefine a default for the <code>when-then-otherwise</code> expression.\nGet the output name of this expression.\nApply window function over a subgroup. This is similar to …\nComputes percentage change between values.\nCompute the pearson correlation between two columns.\nConstant Pi\nPop latest expression and return the input(s) of the …\nRaise expression to the power <code>exponent</code>\nAdd a prefix to the root column name.\nGet the product aggregation of an expression.\nBin continuous values into discrete categories based on …\nBin continuous values into discrete categories using …\nFind a specific quantile of all the values in the column …\nCompute the quantile per group.\nConvert from degrees to radians\nAssign ranks to data, dealing with ties appropriately.\nAnalogous to <code>Iterator::reduce</code>.\nRename the fields of the <code>StructChunked</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nRepeat the column <code>n</code> times, where <code>n</code> is determined by the …\nReplace the given values with other values.\nThe function output type.\nReverse every sublist\nReverse column\nGet the lengths of runs of identical values.\nSimilar to <code>rle</code>, but maps values to run IDs.\nApply a custom function over a rolling/ moving window of …\nApply a custom function over a rolling/ moving window of …\nApply a rolling maximum.\nApply a rolling maximum based on another column.\nApply a rolling mean.\nApply a rolling mean based on another column.\nApply a rolling median.\nApply a rolling median based on another column.\nApply a rolling minimum.\nApply a rolling minimum based on another column.\nApply a rolling quantile.\nApply a rolling quantile based on another column.\nApply a rolling skew.\nApply a rolling std-dev.\nApply a rolling std-dev based on another column.\nApply a rolling sum.\nApply a rolling sum based on another column.\nApply a rolling variance.\nApply a rolling variance based on another column.\nGet the root column names.\nRound underlying floating point array to given decimal …\nRound to a number of significant figures.\nProxy of the number of rows in both sides of the joins …\nFind indices where elements should be inserted to maintain …\nReturn the SET DIFFERENCE between both list arrays.\nReturn the SET INTERSECTION between both list arrays.\nSet this <code>Series</code> as <code>sorted</code> so that downstream code can use …\nReturn the SET SYMMETRIC DIFFERENCE between both list …\nShift every sub-array.\nShift every sublist.\nShift the values in the array by some period. See the …\nShift the values in the array by some period and fill the …\nShrink numeric columns to the minimal required datatype …\nCompute the sign of the given expression\nCompute the sine of the given expression\nCompute the hyperbolic sine of the given expression\nCompute the sample skewness of a data set.\nSlice every sublist.\nSlice the Series. <code>offset</code> may be negative.\nSort every sublist.\nSort with given options.\nSort this column by the ordering of another column …\nCompute the spearman rank correlation between two columns. …\nCompute the square root of the given expression\nCompute the std of the items in every subarray.\nStandard deviation of the values of the Series.\nGet the <code>string::StringNameSpace</code>\nIf set then polars will return an error if any date …\nCast expression to another data type. Throws an error if …\nGet the <code>struct_::StructNameSpace</code>.\nAdd a suffix to the root column name.\nSum all the values in the column named <code>name</code>. Shorthand for …\nCompute the sum of the items in every subarray.\nCompute the sum the items in every sublist.\nReduce groups to the sum of all the values.\nSum all values horizontally across columns.\nGet the tail of every sublist\nGet the last <code>n</code> elements of the Expr result.\nCompute the tangent of the given expression\nCompute the hyperbolic tangent of the given expression\nAdd a condition to the <code>when-then-otherwise</code> expression.\nCreate a column of time ranges from a <code>start</code> and <code>stop</code> …\nConvert a List column into an Array column with the same …\nGet Field result of the expression. The schema is the …\nCast the Array column to List column with the same inner …\nUpdate the root column name to use lowercase characters.\nMap to a physical type.\nConvert this <code>List</code> to a <code>Series</code> of type <code>Struct</code>. The width …\nUpdate the root column name to use uppercase characters.\nReturns the <code>k</code> largest elements.\nReturns the <code>k</code> largest rows by given column.\nMap a single dtype with a potentially failing mapper …\nMap all dtypes with a potentially failing mapper function.\nMap a single field with a potentially failing mapper …\nUndo any renaming operation like <code>alias</code>, <code>keep_name</code>.\nReturn the SET UNION between both list arrays.\nKeep only the unique values in every sub-array.\nKeep only the unique values in every sublist.\nGet unique values of this expression.\nReturns a count of the unique values in the order of …\nKeep only the unique values in every sub-array.\nKeep only the unique values in every sublist.\nGet unique values of this expression, while maintaining …\nGet maximal value that could be hold by this dtype.\nCount all unique values and create a struct mapping value …\nCompute the var of the items in every subarray.\nVariance of the values of the Series.\nStart a <code>when-then-otherwise</code> expression.\nAttach a statement to the corresponding condition.\nAdd another condition to the <code>when-then-otherwise</code> …\nSet the day\nSet the days\nSet a dtype.\nSet <code>milliseconds</code>, <code>microseconds</code>, and <code>nanoseconds</code>\nSet <code>hour</code>, <code>minute</code>, and <code>second</code>\nSet <code>hours</code>, <code>minutes</code>, and <code>seconds</code>\nSet the hour\nSet the hours\nSet the microsecond\nSet the microseconds\nSet the milliseconds\nSet the minute\nSet the minutes\nSet the month\nSet the nanoseconds\nField with the same dtype.\nSet the second\nSet the seconds\nSet the weeks\nSet the year\n“xor” operation.\nfunction to apply\nAlso has the input. i.e. avg(“foo”)\nfunction to apply\nfunction arguments\nfunction arguments\nlength is not yet known so we accept negative offsets\noutput dtype of the function\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if a binary value contains a literal binary.\nCheck if a binary value ends with the given sequence.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck if a binary value starts with the given sequence.\nSpecialized expressions for Categorical dtypes.\nSpecialized expressions for <code>Series</code> with dates/datetimes.\nAdd a given number of business days.\nGet the base offset from UTC.\nChange the underlying <code>TimeUnit</code>. And update the data …\nGet the century of a Date/Datetime\nCombine an existing Date/Datetime with a Time, creating a …\nChange the underlying <code>TimeZone</code> of the <code>Series</code>. This does …\nGet the (local) date of a Date/Datetime.\nGet the (local) datetime of a Datetime.\nGet the month of a Date/Datetime.\nGet the additional offset from UTC currently in effect …\nReturns the argument unchanged.\nGet the hour of a Datetime/Time64.\nCalls <code>U::from(self)</code>.\nGet the iso-year of a Date/Datetime. This may not …\nGet the microsecond of a Time64 (scaled from nanosecs).\nGet the millennium of a Date/Datetime\nGet the millisecond of a Time64 (scaled from nanosecs).\nGet the minute of a Datetime/Time64.\nGet the month of a Date/Datetime.\nRoll forward to the last day of the month.\nRoll backward to the first day of the month.\nGet the nanosecond part of a Time64.\nOffset this <code>Date/Datetime</code> by a given offset <code>Duration</code>. This …\nGet the ordinal_day of a Date/Datetime.\nExtract quarter from underlying NaiveDateTime …\nRound the Datetime/Date range into buckets.\nGet the second of a Datetime/Time64.\nConvert from Date/Time/Datetime into String with the given …\nGet the (local) time of a Date/Datetime/Time.\nReturn the timestamp (UNIX epoch) of a Datetime/Date.\nConvert from Date/Time/Datetime into String with the given …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nTruncate the Datetime/Date range into buckets.\nExtract the week from the underlying Date representation. …\nExtract the ISO week day from the underlying Date …\nChange the underlying <code>TimeUnit</code> of the <code>Series</code>. This does …\nGet the year of a Date/Datetime\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nCreate a new column with the bitwise-and of the elements …\nCreate a new column with the bitwise-or of the elements in …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nGenerate a range of integers.\nFind the indexes that would sort these series in order of …\nGet the indices where <code>condition</code> evaluates <code>true</code>.\nTake several expressions and collect them into a …\nFind the mean of all the values in the column named <code>name</code>. …\nCasts the column given by <code>Expr</code> to a different type.\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nCollect all <code>LazyFrame</code> computations.\nSelect multiple columns by name.\nConcat multiple <code>LazyFrame</code>s vertically.\nConcat LazyFrames diagonally. Calls <code>concat</code> internally.\nConcat LazyFrames horizontally.\nConcat lists entries.\nHorizontally concat string columns in linear time\nCompute the covariance between two columns.\nAccumulate over multiple columns horizontally / row wise.\nAccumulate over multiple columns horizontally / row wise.\nCreate a date range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of date ranges from a <code>start</code> and <code>stop</code> …\nConstruct a column of <code>Datetime</code> from the provided …\nCreate a datetime range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of datetime ranges from a <code>start</code> and <code>stop</code> …\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nAccumulate over multiple columns horizontally / row wise.\nFormat the results of an array of expressions using a …\nSelect multiple columns by index.\nGenerate a range of integers.\nGenerate a range of integers for each row of the input …\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nApply a closure on the two columns that are evaluated from …\nFind the maximum of all the values in the column named <code>name</code>…\nFind the mean of all the values in the column named <code>name</code>. …\nFind the median of all the values in the column named <code>name</code>…\nFind the minimum of all the values in the column named <code>name</code>…\nNegates a boolean column.\nCompute the pearson correlation between two columns.\nFind a specific quantile of all the values in the column …\nAnalogous to <code>Iterator::reduce</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nCompute the spearman rank correlation between two columns. …\nSum all the values in the column named <code>name</code>. Shorthand for …\nGenerate a time range.\nCreate a column of time ranges from a <code>start</code> and <code>stop</code> …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if this column of strings contains a Regex. If <code>strict</code>…\nCheck if a string value contains a literal substring.\nCount all successive non-overlapping regex matches.\nCheck if a string value ends with the <code>sub</code> string.\nExtract a regex pattern from the a string value. If …\nExtract each successive non-overlapping match in an …\nFind the index of a substring defined by a regular …\nFind the index of a literal substring within another …\nReturns the argument unchanged.\nTake the first <code>n</code> characters of the string values.\nCalls <code>U::from(self)</code>.\nConcat the values into a string array.\nReturn the length of each string as the number of bytes.\nReturn the length of each string as the number of …\nPad the end of the string until it reaches the given …\nPad the start of the string until it reaches the given …\nReplace values that match a regex <code>pat</code> with a <code>value</code>.\nReplace all values that match a regex <code>pat</code> with a <code>value</code>.\nReplace values that match a regex <code>pat</code> with a <code>value</code>.\nReverse each string\nSlice the string values.\nSplit the string by a substring. The resulting dtype is …\nSplit exactly <code>n</code> times by a given substring. The resulting …\nSplit exactly <code>n</code> times by a given substring and keep the …\nSplit the string by a substring and keep the substring. …\nSplit by a given substring, returning exactly <code>n</code> items. If …\nCheck if a string value starts with the <code>sub</code> string.\nRemove leading and trailing characters, or whitespace if …\nRemove trailing characters, or whitespace if matches is …\nRemove leading characters, or whitespace if matches is …\nRemove prefix.\nRemove suffix.\nConvert a String column into a Date/Datetime/Time column.\nTake the last <code>n</code> characters of the string values.\nConvert a String column into a Date column.\nConvert a String column into a Datetime column.\nConvert a String column into a Decimal column.\nParse string in base radix into decimal.\nConvert all characters to lowercase.\nConvert a String column into a Time column.\nConvert all characters to titlecase.\nConvert all characters to uppercase.\nPad the start of the string with zeros until it reaches …\nRepresents a user-defined function\nThe function implementation.\nThe function signature.\nname\nOptions for the function.\nThe function output type.\nAllowedOptimizations\nReads LazyFrame from a filesystem or a cloud storage. …\nLazy abstraction over an eager <code>DataFrame</code>. It really is an …\nUtility struct for lazy group_by operation.\nState of the allowed optimizations\nRun every node eagerly. This turns off multi-node …\nGroup by and aggregate.\nAllow parallel table evaluation.\nLeft anti join this query with another lazy query.\nApply a function over the groups as a new DataFrame.\nCaches the result into a new LazyFrame.\nCancel the query at earliest convenience.\nCast named frame columns, resulting in a new LazyFrame …\nCast all frame columns to the given dtype, resulting in a …\nCloudOptions used to list files.\nCloudOptions used to list files.\nCluster sequential <code>with_columns</code> calls to independent calls.\nCluster sequential <code>with_columns</code> calls to independent calls.\nWhether to coalesce join columns.\nExecute all the lazy operations and collect them into a …\nRun common-subexpression-elimination. This elides …\nRun common-subexpression-elimination. This elides …\nRun common-subplan-elimination. This elides duplicate …\nRun common-subplan-elimination. This elides duplicate …\nRecommended concatenation of LazyFrames from many input …\nRecommended concatenation of LazyFrames from many input …\nReturn the number of non-null elements for each column.\nCreates the Cartesian product from both frames, preserving …\nReturn a String describing the optimized logical plan.\nReturn a String describing the optimized logical plan in …\nReturn a String describing the naive (un-optimized) …\nReturn a String describing the naive (un-optimized) …\nRemoves columns from the DataFrame. Note that it’s …\nDrop rows containing None.\nRun every node eagerly. This turns off multi-node …\nRun every node eagerly. This turns off multi-node …\nReturn a String describing the logical plan.\nApply explode operation. See eager explode.\nReplace simple projections with a faster inlined …\nReplace simple projections with a faster inlined …\nFetch the result. If it is ready, a materialized DataFrame …\nFetch is like a collect operation, but it overwrites the …\nAwait the result synchronously.\nCache file reads.\nCache file reads.\nFill NaN values in the DataFrame with an expression.\nFill None values in the DataFrame with an expression.\nFilter by some predicate expression.\nFinish builder\nGet the final LazyFrame.\nGet the final LazyFrame.\nGet the final LazyFrame.\nGet the final LazyFrame. This method assumes, that path is …\nGet the first row.\nForce parallel table evaluation.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nFull outer join this query with another lazy query.\nGet current optimizations.\nExpand path given via globbing rules.\nPerforms a “group-by” on a <code>LazyFrame</code>, producing a …\nGroup based on a time value (or index value of type Int32, …\nSimilar to <code>group_by</code>, but order of the DataFrame is …\nReturn first n rows of each group\nSelect the join type.\nInner join this query with another lazy query.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet list of files referenced by this reader.\nGet list of files referenced by this reader.\nGeneric function to join two LazyFrames.\nConsume <code>self</code> and return a <code>JoinBuilder</code> to customize a join …\nJoin on null values. By default null values will never …\nGet the last row.\nLeft outer join this query with another lazy query.\nThe expressions you want to join the left table on.\nLimit the DataFrame to the first <code>n</code> rows.\nReduce memory usage at the expense of performance\nApply a function/closure once the logical plan get …\nAggregate all the columns as their maximum values.\nAggregate all the columns as their mean values.\nAggregate all the columns as their median values.\nMelt the DataFrame from wide to long format.\nAggregate all the columns as their minimum values.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nCreate the <code>JoinBuilder</code> with the provided <code>LazyFrame</code> as the …\nAggregate all the columns as the sum of their null value …\nThe expressions you want to join both tables on.\nPath of the scanned file. It can be potentially a glob …\nPolars lazy does not implement a pivot because it is …\nApply predicates/filters as early as possible.\nApply predicates/filters as early as possible.\nProfile a LazyFrame.\nOnly read columns that are used later in the query.\nOnly read columns that are used later in the query.\nAggregate all the columns as their quantile values.\nRechunk the memory to contiguous chunks when parsing is …\nRename columns in the DataFrame.\nReverse the <code>DataFrame</code> from top to bottom.\nThe expressions you want to join the right table on.\nCreate rolling groups based on a time column.\nTry to estimate the number of rows so that joins can …\nTry to estimate the number of rows so that joins can …\nAdd a row index column.\nReturn the row index settings.\nAdd a row index column.\nCreate a LazyFrame directly from a ipc scan.\nCreate a LazyFrame directly from a parquet scan.\nCreate a LazyFrame directly from a parquet scan.\nGet a handle to the schema — a map from column names to …\nSelect (and optionally rename, with <code>alias</code>) columns from …\nLeft semi join this query with another lazy query.\nShift the values by a given period and fill the parts that …\nShift the values by a given period and fill the parts that …\nRun many expression optimization rules until fixed point.\nRun many expression optimization rules until fixed point.\nStream a query result into an csv file. This is useful if …\nStream a query result into an ipc/arrow file. This is …\nStream a query result into an ipc/arrow file on an …\nStream a query result into a json file. This is useful if …\nStream a query result into a parquet file. This is useful …\nStream a query result into a parquet file on an …\nSlice the DataFrame using an offset (starting row) and a …\nPushdown slices/limits.\nPushdown slices/limits.\nAdd a sort operation to the logical plan.\nAdd a sort operation to the logical plan.\nAggregate all the columns as their standard deviation …\nRun nodes that are capably of doing so on the streaming …\nRun nodes that are capably of doing so on the streaming …\nSuffix to add duplicate column names in join. Defaults to …\nAggregate all the columns as their sum values.\nGet the last <code>n</code> rows.\nReturn last n rows of each group\nGet a dot language representation of the LogicalPlan.\nRun many type coercion optimization rules until fixed …\nRun many type coercion optimization rules until fixed …\nDrop non-unique rows without maintaining the order of kept …\nDrop non-unique rows and maintain the order of kept rows.\nUnnest the given <code>Struct</code> columns: the fields of the <code>Struct</code> …\nAggregate all the columns as their variance values.\nThe right table in the join.\nCache the DataFrame after reading.\nToggle cluster with columns optimization.\nAdd or replace a column, given as an expression, to a …\nAdd or replace multiple columns, given as expressions, to …\nAdd or replace multiple columns to a DataFrame, but …\nToggle common subexpression elimination optimization on or …\nToggle common subplan elimination optimization on or off\nSet the comment prefix for this instance. Lines starting …\nOverwrite the schema with the dtypes in this given Schema. …\nSet  <code>CsvEncoding</code>\nSet the <code>char</code> used as end of line. The default is <code>b&#39;\\n&#39;</code>.\nExpand path given via globbing rules.\nSet whether the CSV file has headers\nContinue with next batch when a ParserError is encountered.\nSet values as <code>Null</code> if parsing fails because of schema …\nSet the number of rows to use when inferring the csv …\nSet the number of rows to use when inferring the json …\nReduce memory usage at the expense of performance\nTreat missing fields as null.\nConfigure the row limit.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nSet values that will be interpreted as missing/ null.\nSet allowed optimizations.\nSet path of the scanned file. Support glob patterns.\nSet paths of the scanned files. Doesn’t glob patterns.\nToggle predicate pushdown optimization.\nToggle projection pushdown optimization.\nSet the <code>char</code> used as quote char. The default is <code>b&#39;&quot;&#39;</code>. If …\nRaise an error if CSV is empty (otherwise return an empty …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nTry to estimate the number of rows so that joins can …\nConfigure the row index.\nAdd a new column at index 0 that counts the rows.\nAdd a row index column.\nAdd a row index column.\nSet the CSV file’s schema\nSet the JSON file’s schema\nModify a schema before we run the lazy scanning.\nSet the CSV file’s column separator as a byte character\nToggle expression simplification optimization on or off.\nSkip the first <code>n</code> rows during parsing. The header will be …\nSkip this number of rows after the header location.\nToggle slice pushdown optimization.\nRun nodes that are capably of doing so on the streaming …\nTruncate lines that are longer than the schema.\nAutomatically try to parse dates/datetimes and time. If …\nToggle type coercion optimization.\nTurn off all optimizations.\nExecutors will evaluate physical expressions and collect …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nA raw binary array\nA binary true or false.\nCache the input at this point in the LP\nOptions for writing CSV files.\nIn memory DataFrame\nRemove duplicates from the table\nThis allows expressions to access other tables\nFilter on a boolean mask\nA 32-bit floating point number.\nA 64-bit floating point number.\nGroupby aggregation\nHorizontal concatenation of multiple plans\nAdding columns to the table without a Join\nA 16-bit integer number.\nA 32-bit integer number.\nA 64-bit integer number.\nAn 8-bit integer number.\nJoin operation\nNo unique checks\nCheck if join keys are unique in right dataset.\nA (User Defined) Function\nThe literal Null\nCheck if join keys are unique in left dataset.\nCheck if join keys are unique in both left and right …\nPolars’ <code>select</code> operation, this can mean projection, but …\nSlice the table\nSort the table\nA UTF8 encoded string type.\nAn unsigned 16-bit integer number.\nAn unsigned 32-bit integer number.\nAn unsigned 64-bit integer number.\nAn unsigned 8-bit integer number.\nVertical concatenation\nspecify if the scan provider should allow predicate …\nspecify if the scan provider should allow projection …\nspecify if the scan provider should allow slice pushdowns\nData page compression\nData page compression\nCompute the schema. This requires conversion to <code>IR</code> and …\nif <code>None</code> will be 1024^2 bytes\nStart a window at this interval.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGetter for the <code>DataType</code> of the value\nAdd the boundaries to the DataFrame.\nTime or index column.\nTime or index column.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns whether the duration consists of full days.\n<code>true</code> if zero duration.\nTruncate the time column values to the window.\nLiteral expression.\nmaintain the order the data was processed\nmaintain the order the data was processed\nmaintain the order the data was processed\nReturns the nanoseconds from the <code>Duration</code> without the …\nReturns whether duration is negative.\nCreate a new integer size <code>Duration</code>\nOffset window boundaries.\nParse a string into a <code>Duration</code>\nWindow duration.\nWindow duration.\nIf <code>None</code> will be all written to a single row group.\nCreates a DataFrame from the supplied function &amp; scan …\nfunction to supply the schema. Allows for an optional …\nCompute and write column statistics.")