searchState.loadedDescShard("polars", 0, "Polars: <em>DataFrames in Rust</em>\nPolars crate version\nThe typed heart of every Series column.\nData types supported by Polars.\nEnable the global string cache.\nDataFrame module.\nFunctions\nType agnostic columnar data structure.\nTesting utilities.\nCheck whether the global string cache is enabled.\nChunkedArray\nReturns whether all values in the array are <code>true</code>.\nReturns whether all values in the column are <code>true</code>.\nThis is an iterator over a <code>ArrayChunked</code> that save …\nThis is an iterator over a <code>ListChunked</code> that saves …\nSee <code>amortized_iter</code>.\nThis is an iterator over a <code>ArrayChunked</code> that save …\nReturns whether any of the values in the column are <code>true</code>.\nReturns whether any of the values in the column are <code>true</code>.\nAppend in place. This is done by adding the chunks of <code>other</code>…\nApply a closure <code>F</code> elementwise.\nApply a closure <code>F</code> elementwise.\nApply a closure <code>F</code> elementwise.\nApply a closure <code>F</code> to each array.\nCast a numeric array to another numeric data type and …\nApplies a function only to the non-null elements, …\nUtility that reuses an string buffer to amortize …\nIgnore the list indices and apply <code>func</code> to the inner type …\nIgnore the list indices and apply <code>func</code> to the inner type …\nApply a closure <code>F</code> elementwise.\nPanics\nPanics\nPanics\nImplementations of arithmetic operations on ChunkedArray’…\nImplementations of the ChunkCast Trait.\nCast a numeric array to another numeric data type and …\nReturns an iterator over the lengths of the chunks of the …\nA reference to the chunks\nA mutable reference to the chunks\nMethods for collecting into a ChunkedArray.\nReturns the values of the array as a contiguous slice.\nCopies <code>Metadata</code> properties specified by <code>props</code> from <code>other</code> …\nCopies <code>Metadata</code> properties specified by <code>props</code>  from <code>other</code> …\nGet slices of the underlying arrow data. NOTE: null values …\nGet data type of <code>ChunkedArray</code>.\nGet a reference to the used <code>Metadata</code>\nExtend the memory backed by this array with the values …\nGet the index of the first non null value in this …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a new <code>ChunkedArray</code> from existing chunks.\nCreate a new <code>ChunkedArray</code> from existing chunks.\nCreate a new ChunkedArray from an iterator.\nCreate a new ChunkedArray from an iterator.\nCreate a new ChunkedArray from an iterator.\nCreate a new ChunkedArray from an iterator.\nCreate a new ChunkedArray from an iterator.\nImplementations of upstream traits for <code>ChunkedArray&lt;T&gt;</code>\nCreate a new ChunkedArray by taking ownership of the Vec. …\nCreate a new ChunkedArray from a Vec and a validity mask.\nGet a single value from this <code>ChunkedArray</code>. If the return …\nGet the inner values as <code>Series</code>, ignoring the list offsets.\nGet the inner values as <code>Series</code>\nGet a hold to an object that can be formatted or …\nGet a hold to an object that can be formatted or …\nGet a single value from this <code>ChunkedArray</code>. If the return …\nReturn if any the chunks in this <code>ChunkedArray</code> have a …\nGet the head of the <code>ChunkedArray</code>\nGet the inner data type of the list.\nGet the inner data type of the fixed size list.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if ChunkedArray is empty.\nGet a mask of the valid values.\nGet a mask of the null values.\nReturns true if contains a single chunk and has no null …\nReturns an iterator over the offsets of this chunked array.\nGet the buffer of bits representing null values\nGet the index of the last non null value in this …\nGet the length of the ChunkedArray\nApply lhs / self\nApply lhs % self\nApply lhs - self\nTake a view of top n elements\nGet a reference to the <code>ChunkedArray</code>’s <code>Metadata</code>\nGet a reference to <code>Arc</code> that contains the <code>ChunkedArray</code>’s …\nGet a mutable reference to the <code>Arc</code> that contains the …\nGet a <code>Arc</code> that contains the <code>ChunkedArray</code>’s <code>Metadata</code>\nCreate a temporary <code>ChunkedArray</code> from a slice.\nCreate a temporary <code>ChunkedArray</code> from a slice.\nName of the <code>ChunkedArray</code>.\nSpecialization that prevents an allocation prefer this …\nCreate a new <code>ChunkedArray</code> and compute its <code>length</code> and …\nCreate a new <code>ChunkedArray</code> and explicitly set its <code>length</code> …\nConvert missing values to <code>NaN</code> values.\nReturn the number of null values in the ChunkedArray.\nTraits for miscellaneous operations on ChunkedArray\nRemove empty chunks.\nCreate <code>ChunkedArray</code> with samples from a Bernoulli …\nCreate <code>ChunkedArray</code> with samples from a Normal …\nCreate <code>ChunkedArray</code> with samples from a Standard Normal …\nCreate <code>ChunkedArray</code> with samples from a Uniform …\nGet a reference to the field.\nRename this <code>ChunkedArray</code>.\nApply a rolling custom function. This is pretty slow …\nApply a rolling custom function. This is pretty slow …\nSample a fraction between 0.0-1.0 of this <code>ChunkedArray</code>.\nSample n datapoints from this <code>ChunkedArray</code>.\nSet the null count directly.\nSet the ‘sorted’ bit meta info.\nShrink the capacity of this array to fit its length.\nSlice the array. The chunks are reallocated the underlying …\nGet the tail of the <code>ChunkedArray</code>\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nTraits and utilities for temporal data.\nConvert an <code>StringChunked</code> to a <code>Series</code> of <code>DataType::Decimal</code>. …\nSafety\nSet the logical type of the <code>ListChunked</code>.\nIf data is aligned in a single chunk and has no Null …\nIf all nested <code>Series</code> have the same length, a 2 dimensional …\nSafety\nConvert to a <code>Vec</code> of <code>Option&lt;T::Native&gt;</code>.\nConvert to a <code>Vec</code> but don’t return <code>Option&lt;T::Native&gt;</code> if …\nTry apply a closure <code>F</code> elementwise.\nTry apply a closure <code>F</code> to each array.\nApplies a function only to the non-null elements, …\nSeries to <code>ChunkedArray&lt;T&gt;</code>\nGet a single value from this <code>ChunkedArray</code>. Null values are …\nSafety\nReturn this <code>ChunkedArray</code> with a new name.\nSet the ‘sorted’ bit meta info.\nZip with a <code>ChunkedArray</code> then apply a binary function <code>F</code> …\nZip with a <code>ChunkedArray</code> then apply a binary function <code>F</code> …\nAppends from an iterator over values\nAppends from an iterator over values\nAppends a null slot into the builder\nAppends a null slot into the builder\nAppends a null slot into the builder\nAppends a null slot into the builder\nAppends a value of type <code>T</code> into the builder\nAppends a value of type <code>T</code> into the builder\nAppends a value of type <code>T</code> into the builder\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a new ChunkedArray from an iterator.\nCreate a new ChunkedArray from an iterator.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new StringChunkedBuilder\nOverflow is replaced with null\nAllows wrapping overflow\nRaises on overflow\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe no null iterator for a <code>BooleanArray</code>\nA <code>PolarsIterator</code> is an iterator over a <code>ChunkedArray</code> which …\nWrapper struct to convert an iterator of type <code>T</code> into one …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\ncreate a new iterator\ncreate a new iterator\nGet a flags value with all known bits set.\nGet a flags value with all known bits set.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nGet the underlying bits value.\nGet the underlying bits value.\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nWhether all set bits in a source flags value are also set …\nWhether all set bits in a source flags value are also set …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nGet a flags value with all bits unset.\nGet a flags value with all bits unset.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nCreate a <code>Metadata</code> with only the properties set in <code>props</code>.\nCreate a <code>Metadata</code> with only the properties set in <code>props</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConvert from a bits value.\nConvert from a bits value.\nConvert from a bits value exactly.\nConvert from a bits value exactly.\nConvert from a bits value, unsetting any unknown bits.\nConvert from a bits value, unsetting any unknown bits.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nGet a flags value with the bits of a flag with the given …\nGet a flags value with the bits of a flag with the given …\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nWhether any set bits in a source flags value are also set …\nWhether any set bits in a source flags value are also set …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nWhether all known bits in this flags value are set.\nWhether all known bits in this flags value are set.\nWhether all bits in this flags value are unset.\nWhether all bits in this flags value are unset.\nYield a set of contained flags values.\nYield a set of contained flags values.\nYield a set of contained named flags values.\nYield a set of contained named flags values.\nMerge the maximum information from both <code>Metadata</code>s into one …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nCall <code>insert</code> when <code>value</code> is <code>true</code> or <code>remove</code> when <code>value</code> is …\nCall <code>insert</code> when <code>value</code> is <code>true</code> or <code>remove</code> when <code>value</code> is …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nValues need to implement this so that they can be stored …\nTrimmed down object safe polars object\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck validity\nCheck validity\nReturns an iterator of <code>Option&lt;&amp;T&gt;</code> over every element of …\nThis is a heap allocated utility that can be used to …\nSets the validity of this array.\nThis should be used as type information. Consider this a …\nGet a value at a certain index location\nGet a value at a certain index location\nGet a reference to the underlying data\nReturns this array with a new validity.\nAppends a null slot into the builder\nAppends a value of type <code>T</code> into the builder\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThis trait can be registered, after which that global …\nTakes a <code>name</code> and <code>capacity</code> and constructs a new builder.\nAppend a <code>null</code> value.\nAppend a <code>T</code> of <code>ObjectChunked&lt;T&gt;</code> made generic via the <code>Any</code> …\nA function that creates an object builder\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nTake the current state and materialize as a <code>Series</code> the …\nprevious value in array\nAggregation operations.\nFastest way to do elementwise operations on a …\nApply kernels on the arrow array chunks in a ChunkedArray.\nCast <code>ChunkedArray&lt;T&gt;</code> to <code>ChunkedArray&lt;N&gt;</code>\nCompare <code>Series</code> and <code>ChunkedArray</code>’s and get a <code>boolean</code> mask …\nCreate a new ChunkedArray filled with values at that index.\nExplode/flatten a List or String Series\nReplace None values with a value\nFilter values by a boolean mask.\nFill a ChunkedArray with one value.\nQuantile and median aggregation.\nReverse a <code>ChunkedArray&lt;T&gt;</code>\nThis differs from ChunkWindowCustom and ChunkWindow by not …\nCreate a <code>ChunkedArray</code> with new values by index or by …\nShift the values of a <code>ChunkedArray</code> by a number of periods.\nSort operations on <code>ChunkedArray</code>.\nGet unique values in a <code>ChunkedArray</code>\nVariance and standard deviation aggregation.\nCombine two <code>ChunkedArray</code> based on some predicate.\nnext value in array\nMask the first unique values as <code>true</code>\nMask the last unique values as <code>true</code>\nmaximum value in array\nreplace with the maximum value of that data type\nmean value of array\nminimal value in array\nreplace with the minimal value of that data type\nNo value.\nreplace with the value one\nUtility trait to slice concrete arrow arrays whilst …\nSome value of type <code>T</code>.\nSort options for multi-series sorting.\nOptions for single series sorting.\nreplace with the value zero\nApply a closure elementwise including null values.\nApply kernel and return result as a new ChunkedArray.\nApply a kernel that outputs an array of different type.\nApply a closure elementwise and write results to a mutable …\nApply a closure elementwise. This is fastest when the null …\nRetrieve the indexes needed to sort this array.\nRetrieve the indexes need to sort this and the other …\nGet first index of the unique values in a <code>ChunkedArray</code>. …\nCast a <code>ChunkedArray</code> to <code>DataType</code>\nDoes not check if the cast is a valid one and may …\nCast a <code>ChunkedArray</code> to <code>DataType</code>\nIf true sort in descending order. Default <code>false</code>.\nOrder of the columns. Default all `false``.\nCheck for equality.\nCheck for equality where <code>None == None</code>.\nReplace None values with a give value <code>T</code>.\nFilter values in the ChunkedArray with a boolean mask.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a ChunkedArray with a single value.\nGet a single value. Beware this is slow.\nGet a single value. Beware this is slow. If you need to …\nGreater than comparison.\nGreater than or equal comparison.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLess than comparison.\nLess than or equal comparison\nIf true maintain the order of equal elements. Default <code>false</code>…\nWhether maintain the order of equal elements. Default <code>false</code>…\nReturns the maximum value in the array, according to the …\nReturns the mean value in the array. Returns <code>None</code> if the …\nReturns the mean value in the array. Returns <code>None</code> if the …\nIf true sort in multiple threads. Default <code>true</code>.\nWhether sort in multiple threads. Default <code>true</code>.\nNumber of unique values in the <code>ChunkedArray</code>\nCreate <code>SortOptions</code> with default values.\nCreate <code>SortMultipleOptions</code> with default values.\nCreate a new ChunkedArray filled with values at that index.\nCheck for inequality.\nCheck for inequality where <code>None == None</code>.\nWhether place null values last. Default <code>false</code>.\nWhether place null values last. Default <code>false</code>.\nAggregate a given quantile of the ChunkedArray. Returns …\nReturn a reversed version of this array.\nSet the values at indexes <code>idx</code> to some optional value …\nSet the values at indexes <code>idx</code> by applying a closure to …\nSet the values where the mask evaluates to <code>true</code> to some …\nShift the values by a given period and fill the parts that …\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nReturned a sorted <code>ChunkedArray</code>.\nCompute the standard deviation of this ChunkedArray/Series.\nAggregate the sum of the ChunkedArray. Returns <code>None</code> if not …\nGather values from ChunkedArray by index.\nGather values from ChunkedArray by index.\nGet unique values of a ChunkedArray\nCompute the variance of this ChunkedArray/Series.\nWhether maintain the order of equal elements. Default <code>false</code>…\nWhether to maintain the order of equal elements. Default …\nWhether sort in multiple threads. Default <code>true</code>.\nWhether to sort in multiple threads. Default <code>true</code>.\nWhether place null values last. Default <code>false</code>.\nWhether to place null values last. Default <code>false</code>.\nSpecify whether to place nulls last, per-column. Defaults …\nSpecify sorting order for the column. Default <code>false</code>.\nImplement order for all columns. Default <code>false</code>.\nSpecify order for each column. Defaults all <code>false</code>.\nReverse the order of sorting.\nReverse the order of sorting for each column.\nCreate a new ChunkedArray with values from self where the …\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>ArrayRef</code> of the same type.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>ArrayRef</code> of the same type.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nSafety\nSafety\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSearch through a series of chunks for the first position …\nUtility trait to slice concrete arrow arrays whilst …\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nReturn the indices of the bottom k elements.\nUtility trait to slice concrete arrow arrays whilst …\nSort options for multi-series sorting.\nOptions for single series sorting.\nIf true sort in descending order. Default <code>false</code>.\nOrder of the columns. Default all `false``.\nIf true maintain the order of equal elements. Default <code>false</code>…\nWhether maintain the order of equal elements. Default <code>false</code>…\nIf true sort in multiple threads. Default <code>true</code>.\nWhether sort in multiple threads. Default <code>true</code>.\nWhether place null values last. Default <code>false</code>.\nWhether place null values last. Default <code>false</code>.\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nConvert fixed offset to Etc/GMT one from time zone database\nA nested list with a fixed size in each row\nThe set of supported logical types in this crate.\nThe time units defined in Arrow.\nOpaque binary data of variable length whose offsets are …\nA binary type that inlines small values and can intern …\nA binary true or false.\n<code>true</code> and <code>false</code>.\nA 32-bit date representing the elapsed time since UNIX …\nA 32-bit date representing the elapsed time since UNIX …\nAn <code>i32</code> representing the elapsed time since UNIX epoch …\nAn <code>i64</code> representing the elapsed time since UNIX epoch …\nA 64-bit date representing the elapsed time since UNIX …\nA 64-bit date representing the elapsed time since UNIX …\nA 128-bit fixed point decimal number.\nFixed point decimal type optional precision and …\nDecimal value with precision and scale precision is the …\nDecimal backed by 256 bits\nA dictionary encoded array (<code>key_type</code>, <code>value_type</code>), where …\nMeasure of elapsed time. This elapsed time is a physical …\nExtension type.\nCharacterizes the name and the <code>DataType</code> of a column.\nOpaque binary data of fixed size. Enum parameter specifies …\nA list of some logical data type with a fixed number of …\nAn 16-bit float\nA 32-bit floating point number.\nA <code>f32</code>\nA 64-bit floating point number.\nA <code>f64</code>\nHashmap: maps the indexes from the global …\nA 16-bit integer number.\nAn <code>i16</code>\nA 32-bit integer number.\nAn <code>i32</code>\nA 64-bit integer number.\nAn <code>i64</code>\nAn 8-bit integer number.\nAn <code>i8</code>\nA “calendar” interval modeling elapsed time that takes …\nOpaque binary data of variable length whose offsets are …\nA list of some logical data type whose offsets are …\nA variable-length UTF-8 encoded string whose offsets are …\nNested type, contains arrays that are filled with one of …\nA nested list with a variable size in each row\nA list of some logical data type whose offsets are …\nUtf8Array: caches the string values and a hash of all …\nMaps a logical type to a chunked array implementation of …\nA nested type that is represented as\nTime in microseconds.\nTime in milliseconds.\nTime in nanoseconds.\nNull type\nCan be used to fmt and implements Any, so can be …\nA generic type that can be used in a <code>Series</code> &amp;’static str …\nThis hashmap uses an IdHasher\nSafety\nTime in seconds.\nA UTF8 encoded string type.\nString data\nAn UTF8 encoded string type.\nA nested <code>ArrowDataType</code> with a given number of <code>Field</code>s.\nThis is logical type <code>StructChunked</code> that dispatches most …\nA 64-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA 32-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA <code>i64</code> representing a timestamp measured in <code>TimeUnit</code> with …\nAn unsigned 16-bit integer number.\nAn <code>u16</code>\nAn unsigned 32-bit integer number.\nAn <code>u32</code>\nAn unsigned 64-bit integer number.\nAn <code>u64</code>\nAn unsigned 8-bit integer number.\nAn <code>u8</code>\nA nested datatype that can represent slots of differing …\nA type unknown to Arrow.\nA variable-length UTF-8 encoded string whose offsets are …\nA string type that inlines small values and can intern …\nTrue if all categories are represented in this array. When …\nRetrieve the indexes needed to sort this array.\nCast the leaf types of Lists/Arrays and keep the nesting.\nChange the underlying <code>TimeUnit</code>. And update the data …\nChange the underlying <code>TimeUnit</code>. And update the data …\nSets the <code>Field</code> datatype.\nReturns a reference to the <code>Field</code> datatype.\nExtract the days from a <code>Duration</code>\nGet data type of <code>ChunkedArray</code>.\nGet the matching <code>DataType</code> for this <code>AnyValue</code>`.\nGet access to one of this <code>[StructChunked]</code>’s fields\n<code>str</code> to <code>Categorical</code>\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a <code>CategoricalChunked</code> from an array of <code>idx</code> and an …\nConstruct a new <code>DurationChunked</code> from an iterator over …\nConstruct a new <code>DurationChunked</code> from an iterator over …\nCreate a <code>CategoricalChunked</code> from a categorical indices. …\nConstruct a new <code>DateChunked</code> from an iterator over <code>NaiveDate</code>…\nConstruct a new <code>DateChunked</code> from an iterator over optional …\nConstruct a new <code>DatetimeChunked</code> from an iterator over …\nConstruct a new <code>TimeChunked</code> from an iterator over <code>NaiveTime</code>…\nConstruct a new <code>TimeChunked</code> from an iterator over optional …\nCreate a <code>CategoricalChunked</code> from a fixed list of …\n<code>Categorical</code> to <code>str</code>\nGets <code>AnyValue</code> from <code>LogicalType</code>\nGets AnyValue from LogicalType\nSafety\nGet the categories in this <code>RevMapping</code>\nGet a reference to the mapping of categorical types to the …\nGet the full shape of a multidimensional array.\nGet a reference to the <code>&amp;str</code> contained within <code>AnyValue</code>.\nSafety\nSafety\nExtract hour from underlying NaiveDateTime representation. …\nExtract the hours from a <code>Duration</code>\nGet the inner data type of a nested type.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTry to coerce to an AnyValue with static lifetime. This …\nCheck if this <code>DataType</code> is an array.\nCheck if this <code>DataType</code> is a boolean.\nCheck if this <code>DataType</code> is a Decimal type (of any …\nCheck if this <code>DataType</code> is a basic floating point type …\nCheck if this <code>DataType</code> is an integer.\nCheck if the whole dtype is known.\nCheck if this <code>DataType</code> is a list.\nCheck if this <code>DataType</code> is a logical type\nCheck if this <code>DataType</code> is a basic numeric type (excludes …\nCheck if type is sortable\nCheck if datatype is a primitive type. By that we mean that\nCheck if this <code>DataType</code> is a struct\nCheck if this <code>DataType</code> is a temporal type\nCreate an <code>[Iterator]</code> that iterates over the <code>&amp;str</code> values of …\nGet the absolute inner data type of a nested type.\nGet the length of the <code>RevMapping</code>\nExtract the microseconds from a <code>Duration</code>\nExtract the milliseconds from a <code>Duration</code>\nExtract minute from underlying NaiveDateTime …\nExtract the seconds from a <code>Duration</code>\nReturns a reference to the <code>Field</code> name.\nExtract second from underlying NaiveDateTime …\nExtract the nanoseconds from a <code>Duration</code>\nCreates a new <code>Field</code>.\nOnly implemented for the same types and physical types!\nGet a reference to the physical array (the categories).\nGet a reference to the <code>Field</code> of array.\nRegisters a value to a categorical index without pushing …\nCheck if the categoricals have a compatible mapping\nExtract second from underlying NaiveDateTime …\nExtract the seconds from a <code>Duration</code>\nSets the <code>Field</code> name.\nChange the underlying <code>TimeUnit</code>. This does not modify the …\nChange the underlying <code>TimeUnit</code>. This does not modify the …\nChange the underlying <code>TimeZone</code>. This does not modify the …\nReturned a sorted <code>ChunkedArray</code>.\nConvert from Time into String with the given format. See …\nConvert from Datetime into String with the given format. …\nConvert from Date into String with the given format. See …\nCast <code>AnyValue</code> to the provided data type and return a new …\nConvert to an Arrow data type.\nConverts the <code>Field</code> to an <code>arrow::datatypes::Field</code>.\nConvert to an Arrow Field\nConvert a categorical column to its local representation.\nReturns <code>&amp;self</code> for all but <code>ArrowDataType::Extension</code>. For …\nConvert to the physical data type\nthe <code>PhysicalType</code> of this <code>ArrowDataType</code>.\nConvert from Time into String with the given format. See …\nConvert from Datetime into String with the given format. …\nConvert from Date into String with the given format. See …\nCast <code>AnyValue</code> to the provided data type and return a new …\nReturn whether or not the <code>CategoricalChunked</code> uses the …\nSafety\nHashmap: maps the indexes from the global …\nUtf8Array: caches the string values and a hash of all …\nHashmap: maps the indexes from the global …\nUtf8Array: caches the string values and a hash of all …\nEnable the global string cache as long as the object is …\nDisable and clear the global string cache.\nEnable the global string cache.\nReturns the argument unchanged.\nHold the StringCache\nCalls <code>U::from(self)</code>.\nCheck whether the global string cache is enabled.\nPolars Eager cookbook\nPolars Lazy cookbook\nContains the error value\nContains the success value\nConstant that help with creating error messages dependent …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSet the function that will be called by the <code>polars_warn!</code> …\nKeep any of the unique rows This allows more optimizations\nA contiguous growable collection of <code>Series</code> that have the …\nKeep the first unique row.\nKeep the last unique row.\nKeep None of the unique rows.\nSame as <code>filter</code> but does not parallelize.\nEnsure all the chunks in the <code>DataFrame</code> are aligned.\nApply a closure to a column. This is the recommended way …\nApply a closure to a column at index <code>idx</code>. This is the …\nAggregate all the chunks in the DataFrame to a single …\nAggregate all the chunks in the DataFrame to a single …\nSelect a single column by name.\nSelected multiple columns by name.\nDrop a column by name. This is a pure method and will …\nRemove a column by name and return the column removed.\nDrop columns that are in <code>names</code>.\nDrop columns that are in <code>names</code> without allocating a <code>HashSet</code>…\nReturn a new <code>DataFrame</code> where all null values are dropped.\nGet the data types of the columns in the <code>DataFrame</code>.\nCreates an empty <code>DataFrame</code> usable in a compile time …\nCheck if <code>DataFrame</code>s are equal. Note that <code>None == None</code> …\nCheck if all values in <code>DataFrame</code>s are equal where …\nReturns an estimation of the total (heap) allocated size …\nExplode <code>DataFrame</code> to long format by exploding a column …\nExtend the memory backed by this <code>DataFrame</code> with the values …\nGet a reference to the schema fields of the <code>DataFrame</code>.\nReplace None values with one of the following strategies:\nTake the <code>DataFrame</code> rows by a boolean mask.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nPanics\nCreate a new <code>DataFrame</code> from rows. This should only be used …\nCreate a new <code>DataFrame</code> from rows.\nCreate a new <code>DataFrame</code> from an iterator over rows.\nGet a row in the <code>DataFrame</code>. Beware this is slow.\nGet column index of a <code>Series</code> by name.\nExample\nGet the <code>Vec&lt;String&gt;</code> representing the column names.\nGet a reference to the <code>DataFrame</code> columns.\nGet mutable access to the underlying columns.\nGet a row from a <code>DataFrame</code>. Use of this is discouraged as …\nAmortize allocations by reusing a row. The caller is …\nAmortize allocations by reusing a row. The caller is …\nGet the supertype of the columns in this DataFrame\nGroup DataFrame using a Series column.\nGroup DataFrame using a Series column. The groups are …\nGet the head of the <code>DataFrame</code>.\nGet the height of the <code>DataFrame</code> which is the number of …\nAdd multiple <code>Series</code> to a <code>DataFrame</code>. The added <code>Series</code> are …\nAdd multiple <code>Series</code> to a <code>DataFrame</code>. The added <code>Series</code> are …\nAdd columns horizontally.\nInsert a new column at a given index.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet a mask of all the duplicated rows in the <code>DataFrame</code>.\nReturns <code>true</code> if the <code>DataFrame</code> contains no rows.\nGet a mask of all the unique rows in the <code>DataFrame</code>.\nIterator over the columns as <code>Series</code>.\nIterator over the rows in this <code>DataFrame</code> as Arrow …\nIterator over the rows in this <code>DataFrame</code> as Arrow …\nConvert the <code>DataFrame</code> into a <code>LazyFrame</code>\nAggregate the column horizontally to their max values.\nCompute the mean of all values horizontally across columns.\nUnpivot a <code>DataFrame</code> from wide to long format.\nSimilar to melt, but without generics. This may be easier …\nAggregate the column horizontally to their min values.\nThe number of chunks per column\nCreate a DataFrame from a Vector of Series.\nCreate a new <code>DataFrame</code> but does not check the length or …\nCreate a new <code>DataFrame</code> but does not check the length of …\nCreate a new <code>DataFrame</code> that shows the null counts per …\nPipe different functions/ closure operations that work on …\nPipe different functions/ closure operations that work on …\nPipe different functions/ closure operations that work on …\nRemoves the last <code>Series</code> from the <code>DataFrame</code> and returns it, …\nChecks if the Arc ptrs of the <code>Series</code> are equal\nRename a column in the <code>DataFrame</code>.\nReplace a column with a <code>Series</code>.\nReplace column at index <code>idx</code> with a <code>Series</code>.\nReplace or update a column. The difference between this …\nGet a <code>DataFrame</code> with all the columns in reversed order.\nSample a fraction between 0.0-1.0 of this <code>DataFrame</code>.\nSample n datapoints from this <code>DataFrame</code>.\nGet the <code>DataFrame</code> schema.\nCheck if <code>DataFrame</code>’ schemas are equal.\nSelect column(s) from this <code>DataFrame</code> and return a new …\nSelect a <code>Series</code> by index.\nSelect column(s) from this <code>DataFrame</code> by range and return a …\nSelect column(s) from this <code>DataFrame</code> and return them into …\nSelect with a known schema.\nSelect with a known schema. This doesn’t check for …\nSet the column names.\nGet (height, width) of the <code>DataFrame</code>.\nShift the values by a given period and fill the parts that …\nReturns true if the chunks of the columns do not align and …\nShrink the capacity of this DataFrame to fit its length.\nSlice the <code>DataFrame</code> along the rows.\nReturn a sorted clone of this <code>DataFrame</code>.\nSort <code>DataFrame</code> in place.\nSum all values horizontally across columns.\nGet the tail of the <code>DataFrame</code>.\nTake <code>DataFrame</code> rows by index values.\nSafety\nSafety\nCreate a 2D <code>ndarray::Array</code> from this <code>DataFrame</code>. This …\nTranspose a DataFrame. This is a very expensive operation.\nApply a closure that may fail to a column. This is the …\nApply a closure that may fail to a column at index <code>idx</code>. …\nCreate a new <code>DataFrame</code> from an iterator over rows. This …\nGet column index of a <code>Series</code> by name.\nUnstable distinct. See <code>DataFrame::unique_stable</code>.\nDrop duplicate rows from a <code>DataFrame</code>. <em>This fails when </em>…\nUnnest the given <code>Struct</code> columns. This means that the …\nConcatenate a <code>DataFrame</code> to this <code>DataFrame</code> and return as …\nConcatenate a <code>DataFrame</code> to this <code>DataFrame</code>\nGet the width of the <code>DataFrame</code> which is the number of …\nAdd a new column to this <code>DataFrame</code> or replace an existing …\nAdd a new column to this <code>DataFrame</code> or replace an existing …\nAdds a column to the <code>DataFrame</code> without doing any checks on …\nAdd a new column at index 0 that counts the rows.\nAdd a row index column in place.\nArguments for <code>[DataFrame::melt]</code> function\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nWhether the melt may be done in the streaming engine This …\nReturned by a group_by operation on a DataFrame. This …\nIndexes of the groups, the first index is stored …\nEvery group is indicated by an array where the\nUsed to create the tuples for a group_by operation.\nSlice is always sorted in ascending order.\nAggregate the groups of the group_by operation into lists.\nApply a closure over the groups as a new <code>DataFrame</code>.\nAggregate grouped series and compute the number of values …\nAggregate grouped <code>Series</code> and find the first value per …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the internal representation of the GroupBy operation. …\nGet the internal representation of the GroupBy operation. …\nCreate the tuples need for a group_by operation. * The …\nGet the group_by group indexes.\nGet a mutable reference to the <code>GroupsIdx</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nAggregate grouped <code>Series</code> and return the last value per …\nAggregate grouped series and compute the maximum value per …\nAggregate grouped series and compute the mean per group.\nAggregate grouped <code>Series</code> and determine the median per …\nAggregate grouped series and compute the minimal value per …\nAggregate grouped <code>Series</code> by counting the number of unique …\nApply a closure over the groups as a new <code>DataFrame</code> in …\nAggregate grouped <code>Series</code> and determine the quantile per …\nSelect the column(s) that should be aggregated. You can …\nAggregate grouped <code>Series</code> and determine the standard …\nAggregate grouped series and compute the sum per group.\nSafety\nGet a reference to the <code>GroupsIdx</code>.\nGet a reference to the <code>GroupsSlice</code>.\nAggregate grouped <code>Series</code> and determine the variance per …\nHelper that combines the groups into a parallel iterator …\nSame helper as <code>_agg_helper_idx</code> but for aggregations that …\nSafety\nAn <code>AnyValueBuffer</code> that should be used when we trust the …\nSafety\nWill add the <code>AnyValue</code> into <code>Self</code> and unpack as the physical …\nCoerces a slice of datatypes into a single supertype.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nInfer schema from rows and set the first no null type as …\nInfer the schema of rows by determining the supertype of …\nInfer the schema data types of rows by determining the …\nConcat <code>DataFrame</code>s diagonally. Concat diagonally thereby …\nConcat <code>DataFrame</code>s horizontally. Concat horizontally and …\nMultiple values that are used for all columns\nA single value that’s used for all columns\nAllowedOptimizations\nQuote every field. Always.\nKeep any of the unique rows This allows more optimizations\nA thread-safe reference-counting pointer. ‘Arc’ stands …\nArgmin/ Argmax\nA nested list with a fixed size in each row\nSpecialized expressions for <code>Series</code> of <code>DataType::Array</code>.\nThe set of supported logical types in this crate.\nRepresents Arrow’s metadata of a “column”.\nAn ordered sequence of <code>Field</code>s with associated <code>Metadata</code>.\nThe time units defined in Arrow.\nAutomatically determine over which unit to parallelize …\nselects the last row in the right DataFrame whose ‘on’ …\nprevious value in array\nA raw binary array\nOpaque binary data of variable length whose offsets are …\nA binary type that inlines small values and can intern …\nA binary true or false.\nA binary true or false.\n<code>true</code> and <code>false</code>.\nA valid Brotli compression level.\nCache the input at this point in the LP\nSpecialized expressions for Categorical dtypes.\nUtility struct for the <code>when-then-otherwise</code> expression.\nUtility struct for the <code>when-then-otherwise</code> expression.\nAggregation operations.\nAggregations that return <code>Series</code> of unit length. Those can …\nFastest way to do elementwise operations on a …\nApply kernels on the arrow array chunks in a ChunkedArray.\nCast <code>ChunkedArray&lt;T&gt;</code> to <code>ChunkedArray&lt;N&gt;</code>\nCompare <code>Series</code> and <code>ChunkedArray</code>’s and get a <code>boolean</code> mask …\nCreate a new ChunkedArray filled with values at that index.\nExplode/flatten a List or String Series\nReplace None values with a value\nFilter values by a boolean mask.\nFill a ChunkedArray with one value.\nQuantile and median aggregation.\nReverse a <code>ChunkedArray&lt;T&gt;</code>\nThis differs from ChunkWindowCustom and ChunkWindow by not …\nCreate a <code>ChunkedArray</code> with new values by index or by …\nShift the values of a <code>ChunkedArray</code> by a number of periods.\nSort operations on <code>ChunkedArray</code>.\nGet unique values in a <code>ChunkedArray</code>\nVariance and standard deviation aggregation.\nCombine two <code>ChunkedArray</code> based on some predicate.\nChunkedArray\nParallelize over the columns\nCreate a new DataFrame by reading a csv file.\nWrite a DataFrame to csv.\nOptions for writing CSV files.\nA contiguous growable collection of <code>Series</code> that have the …\nIn memory DataFrame\nA 32-bit date representing the elapsed time since UNIX …\nA 32-bit date representing the elapsed time since UNIX …\nAn <code>i32</code> representing the elapsed time since UNIX epoch …\nAn <code>i64</code> representing the elapsed time since UNIX epoch …\nA 64-bit date representing the elapsed time since UNIX …\nA 64-bit date representing the elapsed time since UNIX …\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nA 128-bit fixed point decimal number.\nFixed point decimal type optional precision and …\nDecimal value with precision and scale precision is the …\nDecimal backed by 256 bits\nA dictionary encoded array (<code>key_type</code>, <code>value_type</code>), where …\nRemove duplicates from the table\nMeasure of elapsed time. This elapsed time is a physical …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nContains the error value\nCan be used in a select statement to exclude a column from …\nExplode the aggregated list and just do a hstack instead …\nExpressions that can be used in various contexts. Queries …\nSpecialized expressions for modifying the name of existing …\nThis allows expressions to access other tables\nExtension type.\nCharacterizes the name and the <code>DataType</code> of a column.\nMetadata for a Parquet file.\nFilter on a boolean mask\nKeep the first unique row.\nOpaque binary data of fixed size. Enum parameter specifies …\nA list of some logical data type with a fixed number of …\nAn 16-bit float\nA 32-bit floating point number.\nA 32-bit floating point number.\nA <code>f32</code>\nA 64-bit floating point number.\nA 64-bit floating point number.\nA <code>f64</code>\nselects the first row in the right DataFrame whose …\nnext value in array\nHashmap: maps the indexes from the global …\nReturned by a group_by operation on a DataFrame. This …\nGroupby aggregation\nIndexes of the groups, the first index is stored …\nEvery group is indicated by an array where the\nMap the group values to the position\nA valid Gzip compression level.\nHorizontal concatenation of multiple plans\nAdding columns to the table without a Join\nThis trait exists to be unify the API of polars Schema and …\nA 16-bit integer number.\nA 16-bit integer number.\nAn <code>i16</code>\nA 32-bit integer number.\nA 32-bit integer number.\nAn <code>i32</code>\nA 64-bit integer number.\nA 64-bit integer number.\nAn <code>i64</code>\nAn 8-bit integer number.\nAn 8-bit integer number.\nAn <code>i8</code>\nA “calendar” interval modeling elapsed time that takes …\nUsed to create the tuples for a group_by operation.\nUsed to convert a <code>ChunkedArray</code>, <code>&amp;dyn SeriesTrait</code> and <code>Series</code>\nCompression codec\nRead Arrows IPC format into a DataFrame\nRead Arrows Stream IPC format into a DataFrame\nWrite a DataFrame to Arrow’s Streaming IPC format\nWrite a DataFrame to Arrow’s IPC format\nMask the first unique values as <code>true</code>\nMask the last unique values as <code>true</code>\nJoin operation\nJoin the groups as ‘List&lt;group_dtype&gt;’ to the row …\nA single JSON array containing each DataFrame row as an …\nThe format to use to write the DataFrame to JSON: <code>Json</code> (a …\nEach DataFrame row is serialized as a JSON object on a …\nReads JSON in one of the formats in <code>JsonFormat</code> into a …\nWrites a DataFrame to JSON.\nSet root name as Alias\nLZ4 (framed)\nOpaque binary data of variable length whose offsets are …\nA list of some logical data type whose offsets are …\nA variable-length UTF-8 encoded string whose offsets are …\nKeep the last unique row.\nReads LazyFrame from a filesystem or a cloud storage. …\nLazy abstraction over an eager <code>DataFrame</code>. It really is an …\nUtility struct for lazy group_by operation.\nA value of type <code>L</code>.\nNested type, contains arrays that are filled with one of …\nA nested list with a variable size in each row\nA list of some logical data type whose offsets are …\nSpecialized expressions for <code>Series</code> of <code>DataType::List</code>.\nUtf8Array: caches the string values and a hash of all …\nMaps a logical type to a chunked array implementation of …\nUtf8 encoding and unknown bytes are replaced with �.\nNo unique checks\nCheck if join keys are unique in right dataset.\nA nested type that is represented as\nA (User Defined) Function\nmaximum value in array\nreplace with the maximum value of that data type\nmean value of array\nArguments for <code>[DataFrame::melt]</code> function\nTime in microseconds.\nTime in milliseconds.\nminimal value in array\nreplace with the minimal value of that data type\nonly useful if periods are weekly\nA string that indicates the start of a comment line. This …\nTuples that map column names to null value of that column\nTime in nanoseconds.\nselects the right in the right DataFrame whose ‘on’ …\nQuote fields only when necessary.\nNever quote any fields, even if it would produce invalid …\nJust a wrapper structure. Useful for certain impl …\nQuote non-numeric fields.\nNo value.\nDon’t parallelize\nNo value.\nKeep None of the unique rows.\nTake the nth column in the <code>DataFrame</code>\nThe literal Null\nNull type\nCan be used to fmt and implements Any, so can be …\nA generic type that can be used in a <code>Series</code> &amp;’static str …\nContains the success value\nreplace with the value one\nCheck if join keys are unique in left dataset.\nCheck if join keys are unique in both left and right …\nState of the allowed optimizations\nExplode the aggregated list and just do a hstack instead …\nThe compression strategy to use for writing Parquet files.\nRead Apache parquet format into a DataFrame.\nArrow-deserialized parquet Statistics of a file\nWrite a DataFrame to Parquet format.\nThis hashmap uses an IdHasher\nSafety\nA <code>PolarsIterator</code> is an iterator over a <code>ChunkedArray</code> which …\nValues need to implement this so that they can be stored …\nQuote style indicating when to insert quotes around a …\nA value of type <code>R</code>.\nParallelize over the row groups\nA map from field/column name (<code>String</code>) to the type of that …\nTime in seconds.\nPolars’ <code>select</code> operation, this can mean projection, but …\nExpressions in this node should only be expanding e.g. …\nOptions to serialize logical types to CSV.\nSeries\nA wrapper trait for any binary closure …\nA wrapper trait for any closure …\nA single byte character that indicates the start of a …\nSlice the table\nSlice is always sorted in ascending order.\nUtility trait to slice concrete arrow arrays whilst …\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSort the table\nSort options for multi-series sorting.\nOptions for single series sorting.\nWrapper type that has special equality properties …\nThe statistics to write\nA UTF8 encoded string type.\nA UTF8 encoded string type.\nString data\nEnable the global string cache as long as the object is …\nAn UTF8 encoded string type.\nA nested <code>ArrowDataType</code> with a given number of <code>Field</code>s.\nA <code>StructArray</code> is a nested <code>Array</code> with an optional validity …\nThis is logical type <code>StructChunked</code> that dispatches most …\nSpecialized expressions for Struct dtypes.\nGather by <code>ChunkId</code>\nA ternary operation if true then “foo” else “bar”\nUtility struct for the <code>when-then-otherwise</code> expression.\nA 64-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA 32-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA <code>i64</code> representing a timestamp measured in <code>TimeUnit</code> with …\nAn unsigned 16-bit integer number.\nAn unsigned 16-bit integer number.\nAn <code>u16</code>\nAn unsigned 32-bit integer number.\nAn unsigned 32-bit integer number.\nAn <code>u32</code>\nAn unsigned 64-bit integer number.\nAn unsigned 64-bit integer number.\nAn <code>u64</code>\nAn unsigned 8-bit integer number.\nAn unsigned 8-bit integer number.\nAn <code>u8</code>\nVertical concatenation\nA nested datatype that can represent slots of differing …\nA type unknown to Arrow.\nRepresents a user-defined function\nUtf8 encoding.\nA variable-length UTF-8 encoded string whose offsets are …\nA string type that inlines small values and can intern …\nUtility struct for the <code>when-then-otherwise</code> expression.\nRepresents a window in time\nPolars flavored window functions.\nZSTD\nreplace with the value zero\nA valid Zstandard compression level.\nSafety\nSafety\nTake elements by a slice of <code>ChunkId</code>s.\nSafety\nTake elements by a slice of optional <code>ChunkId</code>s.\nRun every node eagerly. This turns off multi-node …\nConvert numerical values to their absolute value.\nConvert all values to their absolute/positive value.\nGroup by and aggregate.\nGet the group indexes of the group by operation.\nRename Column.\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nReturns whether all values in the column are <code>true</code>.\nCreate a new column with the bitwise-and of the elements …\nReturns a reference to the underlying allocator.\nAllow parallel table evaluation.\nspecify if the scan provider should allow predicate …\nspecify if the scan provider should allow projection …\nspecify if the scan provider should allow slice pushdowns\n“and” operation.\nReturns whether any of the values in the column are <code>true</code>.\nCreate a new column with the bitwise-or of the elements in …\nAppend expressions. This is done by adding the chunks of …\nApply a closure elementwise including null values.\nApply a function over the groups as a new DataFrame.\nApply a function/closure over the groups. This should only …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nApply kernel and return result as a new ChunkedArray.\nApply a kernel that outputs an array of different type.\nApply a function/closure over the groups with many …\nApply a function/closure over the groups of multiple …\nApply a closure elementwise and write results to a mutable …\nApply a closure elementwise. This is fastest when the null …\nGenerate a range of integers.\nArcs this array into a <code>std::sync::Arc&lt;dyn Array&gt;</code>.\nGet the index of the maximal value\nReturn the index of the maximum value of every sublist\nGet the index value that has the maximum value.\nGet the index of the minimal value\nReturn the index of the minimal value of every sublist\nGet the index value that has the minimum value.\nRetrieve the indexes needed to sort this array.\nGet the index values that would sort this expression.\nRetrieve the indexes needed for a sort.\nFind the indexes that would sort these series in order of …\nRetrieve the indexes need to sort this and the other …\nGet first index of the unique values in a <code>ChunkedArray</code>. …\nGet the first index of unique values of this expression.\nGet first indexes of unique values.\nGet the indices where <code>condition</code> evaluates <code>true</code>.\nGet the <code>array::ArrayNameSpace</code>.\nGet arrow schema of the Ipc Stream File, this is faster …\nGet a hold to self as <code>Any</code> trait reference.\nGet a hold to self as <code>Any</code> trait reference. Only …\nParsing string values and return a <code>DateChunked</code>\nParsing string values and return a <code>DateChunked</code> Different …\nParsing string values and return a <code>DatetimeChunked</code>.\nParsing string values and return a <code>DatetimeChunked</code> …\nProvides a raw pointer to the data.\nRechunk and return a pointer to the start of the Series. …\nTake several expressions and collect them into a …\nParsing string values and return a <code>TimeChunked</code>\nConverts to <code>Arc&lt;T&gt;</code>.\nConverts to <code>Arc&lt;[T]&gt;</code>.\nFind the mean of all the values in the column named <code>name</code>. …\nFill missing value with next non-null.\nGet the <code>binary::BinaryNameSpace</code>\nCompute <code>op(l, r)</code> (or equivalently <code>l op r</code>). <code>l</code> and <code>r</code> must …\nBoxes this array into a <code>Box&lt;dyn Array&gt;</code>.\nCaches the result into a new LazyFrame.\nuse a cache of unique, converted dates to apply the …\ncreates a logical expression with a call of the UDF This …\ncreates a logical expression with a call of the UDF This …\nCancel the query at earliest convenience.\nCasts the column given by <code>Expr</code> to a different type.\nCast named frame columns, resulting in a new LazyFrame …\nCast a <code>ChunkedArray</code> to <code>DataType</code>\nCast expression to another data type.\nCast all frame columns to the given dtype, resulting in a …\nDoes not check if the cast is a valid one and may …\nCast a <code>ChunkedArray</code> to <code>DataType</code>\nCast expression to another data type.\nGet the <code>CategoricalNameSpace</code>.\nCompute the cube root of the given expression\nCeil underlying floating point array to the highest …\nCeil underlying floating point array to the highest …\nSet the labels at the center of the window.\nCalculate the millennium from the underlying NaiveDateTime …\nChecks if the projected columns are equal\nChecks if the projected columns are equal\nChecked integer division. Computes self / rhs, returning …\nGet the lengths of the underlying chunks\nTraits and utilities for temporal data.\nUnderlying chunks.\nUnderlying chunks.\nSet values outside the given boundaries to the boundary …\nClip underlying values to a set boundary.\nSet values above the given maximum to the maximum value.\nClip underlying values to a set boundary.\nSet values below the given minimum to the minimum value.\nClip underlying values to a set boundary.\nMakes a clone of the <code>Arc</code> pointer.\nClone inner ChunkedArray and wrap in a new Arc\nWhich side windows should be closed.\nInterface with cloud storage through the object_store …\nCloudOptions used to list files.\nCluster sequential <code>with_columns</code> calls to independent calls.\nCluster sequential <code>with_columns</code> calls to independent calls.\nComparison for two <code>Arc</code>s.\nFolds the expressions from left to right keeping the first …\nWhether to coalesce join columns.\nCreate a Column Expression based on a column name.\nExecute all the lazy operations and collect them into a …\nCollect all <code>LazyFrame</code> computations.\nSelect multiple columns by name.\nReturns column order for <code>i</code>th column in this file. If …\nColumn (sort) order used for <code>min</code> and <code>max</code> values of each …\nData page compression\nData page compression\nCompute the schema. This requires conversion to <code>IR</code> and …\nConcat multiple <code>LazyFrame</code>s vertically.\nConcat with the values from a second StringChunked.\nRecommended concatenation of LazyFrames from many input …\nConcat LazyFrames diagonally. Calls <code>concat</code> internally.\nConcat LazyFrames horizontally.\nConcat lists entries.\nHorizontally concat string columns in linear time\nCheck if the sub-array contains specific element\nCheck if binary contains given literal\nCheck if strings contain a regex pattern.\nCheck if the list array contain an element\nWhether the schema contains a field named <code>name</code>\nCheck if strings contain a given literal\nCast null arrays to inner type and ensure that all offsets …\nReturn the number of non-null elements for each column.\nCount the values of the Series or Get counts of the group …\nCount all successive non-overlapping regex matches.\nCount all successive non-overlapping regex matches.\nRead the number of rows without parsing columns useful for …\nSafety\nString message for application that wrote this file.\nCreates the Cartesian product from both frames, preserving …\nCreates the Cartesian product from both frames, preserves …\nCumulatively count values from 0 to len.\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative max computed at every …\nGet an array with the cumulative max computed at every …\nGet an array with the cumulative min computed at every …\nGet an array with the cumulative min computed at every …\nGet an array with the cumulative product computed at every …\nGet an array with the cumulative product computed at every …\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative sum computed at every …\nGet an array with the cumulative sum computed at every …\nRun an expression over a sliding window that increases <code>1</code> …\nif <code>None</code> will be 1024^2 bytes\nReturns the <code>Field</code>’s <code>ArrowDataType</code>.\nIts logical <code>ArrowDataType</code>\nData types supported by Polars.\nUsed for <code>DataType::Date</code>.\nCreate a column of date ranges from a <code>start</code> and <code>stop</code> …\nConstruct a column of <code>Datetime</code> from the provided …\nUsed for <code>DataType::Datetime</code>.\nCreate a datetime range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of datetime ranges from a <code>start</code> and <code>stop</code> …\nExtract day from underlying NaiveDate representation. …\nExtract day from underlying NaiveDateTime representation. …\nExtract day from underlying NaiveDateTime representation. …\nExtract the days from a <code>Duration</code>\nDecrements the strong reference count on the <code>Arc&lt;T&gt;</code> …\nDecrements the strong reference count on the <code>Arc&lt;T&gt;</code> …\nCreates an empty str inside an Arc\nCreates a new <code>Arc&lt;T&gt;</code>, with the <code>Default</code> value for <code>T</code>.\nCreates an empty <code>[T]</code> inside an Arc\nCreates an empty CStr inside an Arc\nIf true sort in descending order. Default <code>false</code>.\nOrder of the columns. Default all `false``.\nReturn a String describing the optimized logical plan.\nReturn a String describing the optimized logical plan in …\nReturn a String describing the naive (un-optimized) …\nReturn a String describing the naive (un-optimized) …\nDeserializes the statistics in the column chunks from a …\nDiff every sublist.\nCalculate the n-th discrete difference between values.\nnumber of dictinct values. This is a <code>UInt64Array</code> for …\nCompute the dot/inner product between two expressions.\nAttempt to downcast the <code>Arc&lt;dyn Any + Send + Sync&gt;</code> to a …\nDowncasts the <code>Arc&lt;dyn Any + Send + Sync&gt;</code> to a concrete …\nCreates a new <code>Weak</code> pointer to this allocation.\nRemoves columns from the DataFrame. Note that it’s …\nDrops the <code>Arc</code>.\nDrop NaN values.\nDrop rows containing None.\nDrop null values.\nDrop all null values and return a new Series.\nGet the <code>dt::DateLikeNameSpace</code>\nGet data type of <code>ChunkedArray</code>.\nGet datatype of series.\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nRun every node eagerly. This turns off multi-node …\nRun every node eagerly. This turns off multi-node …\nCheck if strings ends with a substring\nCompare <code>Expr</code> with other <code>Expr</code> on equality.\nEquality for two <code>Arc</code>s.\nCompare <code>Expr</code> with other <code>Expr</code> on equality where <code>None == None</code>…\nCheck for equality.\nCheck for equality where <code>None == None</code>.\nRun any <code>Expr</code> on these lists elements\nStart a window at this interval.\nIf polars may parse matches that not contain the whole …\nExclude a column from a wildcard/regex selection.\nExecutes the given command directly.\nReturn a String describing the logical plan.\nApply explode operation. See eager explode.\nExplode the String/List column.\nExtract the nth capture group from pattern.\nExtract each successive non-overlapping regex match in an …\nExtract each successive non-overlapping regex match in an …\nExtract all capture groups from pattern and return as a …\nReplace simple projections with a faster inlined …\nReplace simple projections with a faster inlined …\nFetch the result. If it is ready, a materialized DataFrame …\nFetch is like a collect operation, but it overwrites the …\nAwait the result synchronously.\nGet field (used in schema)\nRetrieve one of the fields of this <code>StructChunked</code> as a new …\nRetrieve one or multiple of the fields of this …\nReturns the fields of this <code>StructArray</code>.\nThe fields composing this schema.\nCache file reads.\nCache file reads.\nFill NaN values in the DataFrame with an expression.\nReplace the floating point <code>NaN</code> values by a value.\nFill None values in the DataFrame with an expression.\nReplace the null values by a value.\nReplace None values with a give value <code>T</code>.\nFilter values in the ChunkedArray with a boolean mask.\nFilter by boolean mask. This operation clones data.\nFilter by some predicate expression.\nFilter a single column.\nReturns a new <code>ArrowSchema</code> with a subset of all fields …\nReturn the index position of a regular expression …\nReturn the index position of a literal substring in the …\nTake the SerReader and return a parsed DataFrame.\nFinish builder\nRead the file and create the DataFrame.\nGet the final LazyFrame.\nTake the SerReader and return a parsed DataFrame.\nGet the final LazyFrame.\nWrite the given DataFrame in the writer <code>W</code>. Returns the …\nGet the final LazyFrame. This method assumes, that path is …\nFirst column in a DataFrame.\nGet the first row.\nGet first item of every sublist.\nGet the first value in the group.\nAlias for <code>explode</code>.\nUsed for <code>DataType::Float64</code> and <code>DataType::Float32</code>.\nFloor underlying floating point array to the lowest …\nFloor underlying floating point array to the lowest …\nFloor divide <code>self</code> by <code>rhs</code>.\nOptional parameters for the rolling function\nAccumulate over multiple columns horizontally / row wise.\nForce parallel table evaluation.\nFormatting string\nFormat the results of an array of expressions using a …\nFill missing value with previous non-null.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nAllocate a reference-counted slice and move <code>v</code>’s items …\nConverts an <code>OsString</code> into an Arc&lt;OsStr&gt; by moving the …\nConverts a <code>CString</code> into an Arc&lt;CStr&gt; by moving the <code>CString</code> …\nConverts a <code>&amp;CStr</code> into a <code>Arc&lt;CStr&gt;</code>, by copying the contents …\nCreate an atomically reference-counted pointer from a …\nConverts an atomically reference-counted string slice into …\nConverts a <code>Path</code> into an <code>Arc</code> by copying the <code>Path</code> data into …\nCopies the string into a newly allocated Arc&lt;OsStr&gt;.\nConverts a <code>T</code> into an <code>Arc&lt;T&gt;</code>\nConverts a <code>PathBuf</code> into an Arc&lt;Path&gt; by moving the <code>PathBuf</code> …\nMove a boxed object to a new, reference-counted allocation.\nAllocate a reference-counted <code>str</code> and copy <code>v</code> into it.\nReturns the argument unchanged.\nConverts a <code>[T; N]</code> into an <code>Arc&lt;[T]&gt;</code>.\nAllocate a reference-counted <code>str</code> and copy <code>v</code> into it.\nAllocate a reference-counted slice and fill it by cloning <code>v</code>…\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nSafety\nSafety\nTakes each element in the <code>Iterator</code> and collects it into an …\nCreate a list-array from an iterator. Used in group_by …\nSafety\nCreate a list-array from an iterator. Used in group_by …\nCreate a new ChunkedArray from an iterator.\nCreate a list-array from an iterator. Used in group_by …\nCreate a list-array from an iterator. Used in group_by …\nCreate a new ChunkedArray from an iterator.\nThis is the recommended way to create a json reader as …\nConstructs an <code>Arc&lt;T&gt;</code> from a raw pointer.\nConstructs an <code>Arc&lt;T, A&gt;</code> from a raw pointer.\nInitialize by name and values.\nCreate a ChunkedArray with a single value.\nFull outer join this query with another lazy query.\nPerform a full outer join on two DataFrames\nThe function implementation.\nA function that cannot be expressed with <code>map</code> or <code>apply</code> and …\nTake the values by idx.\n‘Greater than or equal to’ comparison for two <code>Arc</code>s.\nGet a single value by index. Don’t use this operation …\nGet items in every sub-array by index.\nGet items in every sublist by index.\nTake the values by a single index.\nGet a reference to the dtype of the field named <code>name</code>, or …\nGet a single value. Beware this is slow.\nGets <code>AnyValue</code> from <code>LogicalType</code>\nGet a single value. Beware this is slow. If you need to …\nSafety\nGet references to the name and dtype of the field at <code>index</code>\nGet mutable references to the name and dtype of the field …\nGet current optimizations.\nGetter for the <code>DataType</code> of the value\nreturns the bounds for the earliest window bounds that …\nLook up the name in the schema and return an owned <code>Field</code> …\nReturns the fields the <code>DataType::Struct</code>.\nReturn all data about the field named <code>name</code>: its index in …\nReturns a mutable reference into the given <code>Arc</code>, if there …\nReturns a mutable reference into the given <code>Arc</code>, without …\nGet a vector of all column names.\nGet the value at this index as a downcastable Any trait …\nGet the value at this index as a downcastable Any trait …\nCompute <code>remaining_rows_to_read</code> to be taken per file up …\nSafety\nSafety\nGet a single value by index. Don’t use this operation …\nExpand path given via globbing rules.\nPerforms a “group-by” on a <code>LazyFrame</code>, producing a …\nGroup based on a time value (or index value of type Int32, …\nSimilar to <code>group_by</code>, but order of the DataFrame is …\nDifferent from <code>group_by_windows</code>, where define window …\nWindow boundaries are created based on the given <code>Window</code>, …\nCreate the tuples need for a group_by operation. * The …\nGreater than comparison.\nCheck if <code>Expr</code> &gt; <code>Expr</code>.\nGreater-than comparison for two <code>Arc</code>s.\nGreater than or equal comparison.\nCheck if <code>Expr</code> &gt;= <code>Expr</code>.\nReturn if any the chunks in this <code>[ChunkedArray]</code> have a …\nReturn first n rows of each group\nGet the head of every sublist\nGet the first <code>n</code> elements of the Expr result.\nHorizontally concatenate all strings.\nExtract hour from underlying NaiveDateTime representation. …\nExtract hour from underlying NaiveDateTime representation. …\nExtract hour from underlying NaiveDateTime representation. …\nExtract the hours from a <code>Duration</code>\nSelect the join type.\nIf <code>ambiguous</code> is length-1 and not equal to “null”, we …\nGroupBy the group to a Series.\nSet whether to write UTF-8 BOM.\nAdd the boundaries to the DataFrame.\nSet whether to write headers.\nIncrements the strong reference count on the <code>Arc&lt;T&gt;</code> …\nIncrements the strong reference count on the <code>Arc&lt;T&gt;</code> …\nSelect multiple columns by index.\nTime or index column.\nTime or index column.\nGet the index of a column by name.\nInfer the schema of a CSV file by reading through the …\nSet the JSON reader to infer the schema of the file. …\nInner join this query with another lazy query.\nPerform an inner join on two DataFrames.\nThe function signature.\nInsert a field with <code>name</code> and <code>dtype</code> at the given <code>index</code> into …\nGenerate a range of integers.\nGenerate a range of integers for each row of the input …\nFill null values using interpolation.\nFill null values using interpolation.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nDeconstructs the <code>StructArray</code> into its individual …\nReturns the inner value, if the <code>Arc</code> has exactly one strong …\nConsumes the <code>Arc</code>, returning the wrapped pointer.\nConsumes the <code>Arc</code>, returning the wrapped pointer and …\nCreates a CSV reader using a file handle.\nSerializes itself to thrift’s …\nCheck if the path is a cloud url.\ncheck if csv file is compressed\nCheck if Series is empty.\nGet mask of finite values if dtype is Float.\nGet a mask of the first unique value.\nReturns whether the duration consists of full days.\nCheck if the values of the left expression are in the …\nGet mask of infinite values if dtype is Float.\nGet a mask of the last unique value.\nExtract year from underlying NaiveDate representation. …\nExtract year from underlying NaiveDate representation. …\nExtract year from underlying NaiveDateTime representation. …\nGet mask of NaN values if dtype is Float.\nGet inverse mask of NaN values if dtype is Float.\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nGet a mask of the non-null values.\nRun is_not_null operation on <code>Expr</code>.\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nGet a mask of the null values.\nRun is_null operation on <code>Expr</code>.\nIts nullability\nMay give false negatives because it ignores the null …\nChecks if a <code>Series</code> is sorted. Tries to fail fast.\n<code>true</code> if zero duration.\nThis year number might not match the calendar year number.\nReturns an iterator of <code>Option&lt;Box&lt;dyn Array&gt;&gt;</code>\nIterates over the <code>(&amp;name, &amp;dtype)</code> pairs in this schema\nIterates over references to the dtypes in this schema\nIterates over mut references to the dtypes in this schema\nIterates the <code>Field</code>s in this schema, constructing them anew …\nIterates over references to the names in this schema\nGet list of files referenced by this reader.\nJoin all string items in a sub-array and place a separator …\nGeneric function to join two LazyFrames.\nJoin all string items in a sublist and place a separator …\nGeneric join method. Can be used to join on multiple …\nThis is similar to a left-join except that we match on …\nThis is similar to a left-join except that we match on …\nConsume <code>self</code> and return a <code>JoinBuilder</code> to customize a join …\nJoin on null values. By default null values will never …\nKeep the original root name\nreturns the metadata\nkey_value_metadata of this file.\nTruncate the time column values to the window.\nLast column in a DataFrame.\nGet the last row.\nGet last item of every sublist.\nGet the last value in the group.\n‘Less than or equal to’ comparison for two <code>Arc</code>s.\nLeft outer join this query with another lazy query.\nPerform a left outer join on two DataFrames\nThe expressions you want to join the left table on.\nReturn the number of rows in the context.\nGet length of series.\nReturn the number of elements in each list.\nThe number of fields in the schema\nLimit the DataFrame to the first <code>n</code> rows.\nTake <code>num_elements</code> from the top as a zero copy view.\nString appended after every row.\nGet the <code>list::ListNameSpace</code>\nCreate a Literal Expression from <code>L</code>. A literal expression …\nLiteral expression.\n“or” operation.\n“or” operation.\nReduce memory usage at the expense of performance\nReduce memory consumption at the expense of performance\nGet minimal value that could be hold by this dtype.\nGet the value by index in the sublists. So index <code>0</code> would …\nIn case the inner dtype <code>DataType::String</code>, the individual …\nLess than comparison.\nCheck if <code>Expr</code> &lt; <code>Expr</code>.\nLess-than comparison for two <code>Arc</code>s.\nLess than or equal comparison\nCheck if <code>Expr</code> &lt;= <code>Expr</code>.\nmaintain the order the data was processed\nmaintain the order the data was processed\nmaintain the order the data was processed\nIf true maintain the order of equal elements. Default <code>false</code>…\nWhether maintain the order of equal elements. Default <code>false</code>…\nMakes a mutable reference into the given <code>Arc</code>.\nApply a function/closure once the logical plan get …\nDefine an alias by mapping a function over the original …\nApply a function/closure once the logical plan get …\nApply a closure on the two columns that are evaluated from …\nSet the timezone of a datetime dtype.\nMap a single dtype.\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nMap to a float supertype if numeric, else preserve\nApply a function to the parse options.\nMap to a float supertype.\nMap the dtype to the dtype of the list/array elements.\nMap the dtypes to the “supertype” of a list of lists.\nMap the dtype to the “supertype” of all fields.\nFind the maximum of all the values in the column named <code>name</code>…\nCompute the maximum of the items in every subarray.\nAggregate all the columns as their maximum values.\nCompute the maximum of the items in every sublist.\nReturns the maximum value in the array, according to the …\nReduce groups to maximum value.\nGet the max of the <code>ChunkedArray</code> as a new <code>Series</code> of length …\nGet the max of the Series as a new Series of length 1.\nMaximum\nFind the mean of all the values in the column named <code>name</code>. …\nAggregate all the columns as their mean values.\nCompute the mean of every sublist and return a <code>Series</code> of …\nReturns the mean value in the array. Returns <code>None</code> if the …\nReduce groups to the mean value.\nReturns the mean value in the array Returns an option …\nFind the median of all the values in the column named <code>name</code>…\nCompute the median of the items in every subarray.\nAggregate all the columns as their median values.\nReturns the mean value in the array. Returns <code>None</code> if the …\nReduce groups to the median value.\nReturns the median value in the array Returns an option …\nGet the median of the <code>ChunkedArray</code> as a new <code>Series</code> of …\nGet the median of the Series as a new Series of length 1.\nMelt the DataFrame from wide to long format.\nSet if the file is to be memory_mapped. Only works with …\nMerge <code>other</code> into <code>self</code>\nMerge borrowed <code>other</code> into <code>self</code>\nAdditional custom (opaque) metadata.\nOptional metadata.\nExtract the microseconds from a <code>Duration</code>\nCalculate the millennium from the underlying NaiveDateTime …\nExtract the milliseconds from a <code>Duration</code>\nFind the minimum of all the values in the column named <code>name</code>…\nCompute the minimum of the items in every subarray.\nAggregate all the columns as their minimum values.\nCompute the minimum of the items in every sublist.\nReduce groups to minimal value.\nAmount of elements in the window that should be filled …\nAmount of elements in the window that should be filled …\nGet the min of the <code>ChunkedArray</code> as a new <code>Series</code> of length …\nGet the min of the Series as a new Series of length 1.\nMinimum\nExtract minute from underlying NaiveDateTime …\nExtract minute from underlying NaiveDateTime …\nExtract minute from underlying NaiveDateTime …\nExtract the minutes from a <code>Duration</code>\nCompute the mode(s) of this column. This is the most …\nExtract month from underlying NaiveDateTime representation.\nExtract month from underlying NaiveDateTime representation.\nExtract month from underlying NaiveDateTime representation.\nIf true sort in multiple threads. Default <code>true</code>.\nWhether sort in multiple threads. Default <code>true</code>.\nNumber of chunks in this Series\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nNumber of unique values in the <code>ChunkedArray</code>\nGet the number of unique values in the groups.\nGet unique values in the Series.\nName of series.\nGet the <code>name::ExprNameNameSpace</code>\nname\nIts name\nReduce groups to maximum value.\nReduce groups to minimal value.\nExtract second from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nReturns the number of nanoseconds since the whole non-leap …\nExtract the nanoseconds from a <code>Duration</code>\nReturns the nanoseconds from the <code>Duration</code> without the …\nInequality for two <code>Arc</code>s.\nReturns whether duration is negative.\nTranslate the negative index to an offset.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality where …\nCreate a new instance of the <code>[SerReader]</code>\nInitialize by name and values.\nCreate the <code>JoinBuilder</code> with the provided <code>LazyFrame</code> as the …\nCreate a new CsvReader from a file/stream using default …\nCreate a new <code>JsonWriter</code> writing to <code>buffer</code> with format …\nCreate a new integer size <code>Duration</code>\nCreate a new JsonLineReader from a file/ stream\nCreate a new <code>ParquetReader</code> from an existing <code>Reader</code>.\nCreate a new writer\nConstruct a new <code>DatetimeArgs</code> set to <code>year</code>, <code>month</code>, <code>day</code>\nCreate a new <code>DurationArgs</code> with all fields set to <code>lit(0)</code>. …\nCreate a new UserDefinedFunction\nConstructs a new <code>Arc&lt;T&gt;</code>.\nReturns a new <code>StructArray</code>\nCreate a new, empty schema\nCreates a new <code>Field</code>.\nConstructs a new <code>Arc&lt;T&gt;</code> while giving you a <code>Weak&lt;T&gt;</code> to the …\nCreates an empty <code>StructArray</code>.\nCreate a new ChunkedArray filled with values at that index.\nCreate a new Series filled with values from the given …\nCreates a new <code>CommentPrefix</code> from a <code>&amp;str</code>.\nConstructs a new <code>Arc&lt;T&gt;</code> in the provided allocator.\nCreate a new schema from this one, inserting a field with …\nCreates a new <code>CommentPrefix</code> for the <code>Multi</code> variant.\nCreates a null <code>StructArray</code> of length <code>length</code>.\nCreates a new <code>CommentPrefix</code> for the <code>Single</code> variant.\nConstructs a new <code>Arc</code> with uninitialized contents.\nConstructs a new <code>Arc</code> with uninitialized contents in the …\nConstructs a new atomically reference-counted slice with …\nConstructs a new atomically reference-counted slice with …\nConstructs a new <code>Arc</code> with uninitialized contents, with the …\nConstructs a new <code>Arc</code> with uninitialized contents, with the …\nConstructs a new atomically reference-counted slice with …\nConstructs a new atomically reference-counted slice with …\nNegates a boolean column.\nNegate <code>Expr</code>.\nCheck for inequality.\nCheck for inequality where <code>None == None</code>.\nNth column in a DataFrame.\nNull value representation.\nCount the null values.\nAggregate all the columns as the sum of their null value …\nGet the null count of the column/group.\nnumber of nulls. This is a <code>UInt64Array</code> for non-nested types\nWhether place null values last. Default <code>false</code>.\nWhether place null values last. Default <code>false</code>.\nNumber of rows in the parquet file.\nnumber of rows in the file.\nOffset window boundaries.\nThe expressions you want to join both tables on.\nOptions for the function.\n“or” operation.\nReturns the day of year starting from 1.\nReturns the day of year starting from 1.\nReturns the day of year starting from 1.\nExtract ordinal year from underlying NaiveDateTime …\nDefine a default for the <code>when-then-otherwise</code> expression.\nDefine a default for the <code>when-then-otherwise</code> expression.\nApply window function over a subgroup. This is similar to …\nParse a string into a <code>Duration</code>\nPartial comparison for two <code>Arc</code>s.\nPath of the scanned file. It can be potentially a glob …\nWindow duration.\nWindow duration.\nConstant Pi\nConstructs a new <code>Pin&lt;Arc&lt;T&gt;&gt;</code>. If <code>T</code> does not implement <code>Unpin</code>…\nConstructs a new <code>Pin&lt;Arc&lt;T, A&gt;&gt;</code> in the provided allocator. …\nRaise expression to the power <code>exponent</code>\nApply predicates/filters as early as possible.\nApply predicates/filters as early as possible.\nAdd a prefix to the root column name.\nGet the product of the <code>ChunkedArray</code> as a new <code>Series</code> of …\nGet the product aggregation of an expression.\nProfile a LazyFrame.\nOnly read columns that are used later in the query.\nOnly read columns that are used later in the query.\nReturns <code>true</code> if the two <code>Arc</code>s point to the same allocation …\nFind a specific quantile of all the values in the column …\nAggregate all the columns as their quantile values.\nAggregate a given quantile of the ChunkedArray. Returns …\nCompute the quantile per group.\nGet the quantile of the <code>ChunkedArray</code> as a new <code>Series</code> of …\nGet the quantile of the ChunkedArray as a new Series of …\nExtract month from underlying NaiveDateTime representation.\nExtract quarter from underlying NaiveDateTime …\nExtract quarter from underlying NaiveDateTime …\nQueues the given command for further execution.\nQuoting character.\nWhen to insert quotes.\nAssign ranks to data, dealing with ties appropriately.\nRead the parquet file in parallel (default). The single …\nRechunk the memory to contiguous chunks when parsing is …\nAggregate all chunks to a contiguous array of memory.\nAnalogous to <code>Iterator::reduce</code>.\nSwap-remove a field by name and, if the field existed, …\nRename the Series.\nRename columns in the DataFrame.\nRename field <code>old</code> to <code>new</code>, and return the (owned) old name\nRename the fields of the <code>StructChunked</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nRepeat the column <code>n</code> times, where <code>n</code> is determined by the …\nReplace the leftmost regex-matched (sub)string with …\nReplace the given values with other values.\nReplace all regex-matched (sub)strings with another string\nReplace the leftmost literal (sub)string with another …\nReplace all matching literal (sub)strings with another …\nReserve <code>additional</code> memory spaces in the schema.\nThe function output type.\nReturn a reversed version of this array.\nreturn a Series in reversed order\nReverse the <code>DataFrame</code> from top to bottom.\nReverse every sublist\nReverse column\nThe expressions you want to join the right table on.\nCreate rolling groups based on a time column.\nApply a custom function over a rolling/ moving window of …\nApply a custom function over a rolling/ moving window of …\nApply a custom function over a rolling/ moving window of …\nApply a rolling max to a Series.\nApply a rolling maximum.\nApply a rolling max to a Series based on another Series.\nApply a rolling maximum based on another column.\nApply a rolling mean to a Series.\nApply a rolling mean.\nApply a rolling mean to a Series based on another Series.\nApply a rolling mean based on another column.\nApply a rolling median.\nApply a rolling median based on another column.\nApply a rolling min to a Series.\nApply a rolling minimum.\nApply a rolling min to a Series based on another Series.\nApply a rolling minimum based on another column.\nApply a rolling quantile to a Series.\nApply a rolling quantile.\nApply a rolling quantile to a Series based on another …\nApply a rolling quantile based on another column.\nApply a rolling std_dev to a Series.\nApply a rolling std-dev.\nApply a rolling std_dev to a Series based on another …\nApply a rolling std-dev based on another column.\nApply a rolling sum to a Series.\nApply a rolling sum.\nApply a rolling sum to a Series based on another Series.\nApply a rolling sum based on another column.\nApply a rolling variance to a Series.\nApply a rolling variance.\nApply a rolling variance to a Series based on another …\nApply a rolling variance based on another column.\nRound underlying floating point array to given decimal.\nRound underlying floating point array to given decimal …\nRound the given ms timestamp by the window boundary.\nRound the given ns timestamp by the window boundary.\nRound to a number of significant figures.\nRound the given us timestamp by the window boundary.\nTry to estimate the number of rows so that joins can …\nTry to estimate the number of rows so that joins can …\nIf <code>None</code> will be all written to a single row group.\nThe row groups of this file\nAdd a row index column.\nReturn the row index settings.\nAdd a row index column.\nProxy of the number of rows in both sides of the joins …\nCreates a DataFrame from the supplied function &amp; scan …\nCreate a LazyFrame directly from a ipc scan.\nCreate a LazyFrame directly from a parquet scan.\nCreate a LazyFrame directly from a parquet scan.\nSet the values at indexes <code>idx</code> to some optional value …\nSet the values at indexes <code>idx</code> by applying a closure to …\nGet arrow schema of the Ipc File.\nGet schema of the Ipc Stream File\nGet a handle to the schema — a map from column names to …\n<code>Schema</code> of the file.\nfunction to supply the schema. Allows for an optional …\nReturns the <code>SchemaDescriptor</code> that describes schema of this …\nschema descriptor.\nExtract second from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nExtract the seconds from a <code>Duration</code>\nSelect (and optionally rename, with <code>alias</code>) columns from …\nUsed as separator.\nSet the values where the mask evaluates to <code>true</code> to some …\nChange the field named <code>name</code> to the given <code>dtype</code> and return …\nChange the field at the given index to the given <code>dtype</code> and …\nTry to reduce memory pressure at the expense of …\nSerialize columns in parallel\nMake sure that all columns are contiguous in memory by …\nSet this <code>Series</code> as <code>sorted</code> so that downstream code can use …\nSets the validity of this array.\nShift the values by a given period and fill the parts that …\nShift every sub-array.\nShift the values by a given period and fill the parts that …\nShift every sublist.\nShift the values in the array by some period. See the …\nShift the values by a given period and fill the parts that …\nShift the values by a given period and fill the parts that …\nShift the values in the array by some period and fill the …\nRemove a field by name, preserving order, and, if the …\nRemove a field by name, preserving order, and, if the …\nShrink numeric columns to the minimal required datatype …\nShrink the capacity of this array to fit its length.\nRun many expression optimization rules until fixed point.\nRun many expression optimization rules until fixed point.\nStream a query result into an csv file. This is useful if …\nStream a query result into an ipc/arrow file. This is …\nStream a query result into a json file. This is useful if …\nStream a query result into a parquet file. This is useful …\nGet a zero copy view of the data.\nSlice the DataFrame using an offset (starting row) and a …\nSlice every sublist.\nSlice the Series. <code>offset</code> may be negative.\nSlices this <code>StructArray</code>.\nPushdown slices/limits.\nPushdown slices/limits.\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nSlices this <code>StructArray</code>.\nReturns this array sliced.\nReturns this array sliced.\nReturned a sorted <code>ChunkedArray</code>.\nAdd a sort operation to the logical plan.\nSort every sublist.\nSort with given options.\nSort this column by the ordering of another column …\nAdd a sort operation to the logical plan.\nCompute the square root of the given expression\nCheck if strings starts with a substring\nCompute and write column statistics.\nCompute the std of the items in every subarray.\nAggregate all the columns as their standard deviation …\nCompute the standard deviation of this ChunkedArray/Series.\nStandard deviation of the values of the Series.\nReturns the std value in the array Returns an option …\nGet the standard deviation of the <code>ChunkedArray</code> as a new …\nGet the standard deviation of the Series as a new Series …\nGet the <code>string::StringNameSpace</code>\nSlice the first <code>n</code> values of the string.\nGet the length of the string values as number of bytes.\nGet the length of the string values as number of chars.\nReverses the string values\nSlice the string values.\nSlice the last <code>n</code> values of the string.\nWhether the melt may be done in the streaming engine This …\nRun nodes that are capably of doing so on the streaming …\nRun nodes that are capably of doing so on the streaming …\nConvert from Time into String with the given format. See …\nIf set then polars will return an error if any date …\nCast expression to another data type. Throws an error if …\nGets the number of strong (<code>Arc</code>) pointers to this …\nGet the <code>struct_::StructNameSpace</code>.\nSuffix to add duplicate column names in join. Defaults to …\nAdd a suffix to the root column name.\nSum all the values in the column named <code>name</code>. Shorthand for …\nCompute the sum of the items in every subarray.\nAggregate all the columns as their sum values.\nCompute the sum the items in every sublist.\nAggregate the sum of the ChunkedArray. Returns <code>None</code> if not …\nReduce groups to the sum of all the values.\nGet the sum of the <code>ChunkedArray</code> as a new <code>Series</code> of length …\nGet the sum of the Series as a new Scalar.\nPerforms a set of actions within a synchronous update.\nGet the last <code>n</code> rows.\nReturn last n rows of each group\nGet the tail of every sublist\nGet the last <code>n</code> elements of the Expr result.\nGather values from ChunkedArray by index.\nTake by index. This operation is clone.\nSafety\nSafety\nTake by index. This operation is clone.\nTake by index.\nGather values from ChunkedArray by index.\nTake by index.\nTakes the validity of this array, leaving it without a …\nAdd a condition to the <code>when-then-otherwise</code> expression.\nUsed for <code>DataType::Time</code>.\nCreate a column of time ranges from a <code>start</code> and <code>stop</code> …\nConvert date(time) object to timestamp in <code>TimeUnit</code>.\nConvert a List column into an Array column with the same …\nConvert self to <code>ArrowSchema</code> by cloning the fields\nGet a dot language representation of the LogicalPlan.\nCrea dummy variables.\nGet Field result of the expression. The schema is the …\nCast the Array column to List column with the same inner …\nModify the strings to their lowercase equivalent.\nUpdate the root column name to use lowercase characters.\nMap to a physical type.\nConvert Time into String with the given format. See chrono …\nTake another <code>Schema</code> and try to find the supertypes between …\nModify the strings to their titlecase equivalent.\nModify the strings to their uppercase equivalent.\nUpdate the root column name to use uppercase characters.\nA tolerance in the same unit as the asof column\nA time duration specified as a string, for example:\nTruncate the given ms timestamp by the window boundary.\nTruncate the given ns timestamp by the window boundary.\nTruncate the given us timestamp by the window boundary.\nDeserializes <code>crate::parquet::thrift_format::FileMetaData</code> …\nGet a reference to the dtype of the field named <code>name</code>, or …\nLook up the name in the schema and return an owned <code>Field</code> …\nReturn all data about the field named <code>name</code>: its index in …\nGet a mutable reference to the dtype of the field named …\nCreates a CSV reader using a file path.\nMap a single dtype with a potentially failing mapper …\nMap all dtypes with a potentially failing mapper function.\nMap a single field with a potentially failing mapper …\nConstructs a new <code>Arc&lt;T&gt;</code>, returning an error if allocation …\nReturns a new <code>StructArray</code>.\nConstructs a new <code>Arc&lt;T, A&gt;</code> in the provided allocator, …\nConstructs a new <code>Arc</code> with uninitialized contents, …\nConstructs a new <code>Arc</code> with uninitialized contents, in the …\nConstructs a new <code>Arc</code> with uninitialized contents, with the …\nConstructs a new <code>Arc</code> with uninitialized contents, with the …\nConstructs a new <code>Pin&lt;Arc&lt;T&gt;&gt;</code>, return an error if …\nConstructs a new <code>Pin&lt;Arc&lt;T, A&gt;&gt;</code> in the provided allocator, …\nReturns the inner value, if the <code>Arc</code> has exactly one strong …\nRun many type coercion optimization rules until fixed …\nRun many type coercion optimization rules until fixed …\nThis should be used as type information. Consider this a …\nGet unique values of a ChunkedArray\nKeep only the unique values in every sub-array.\nDrop non-unique rows without maintaining the order of kept …\nKeep only the unique values in every sublist.\nGet unique values of this expression.\nGet unique values in the Series.\nKeep only the unique values in every sub-array.\nDrop non-unique rows and maintain the order of kept rows.\nKeep only the unique values in every sublist.\nGet unique values of this expression, while maintaining …\nUnnest the given <code>Struct</code> columns: the fields of the <code>Struct</code> …\nIf we have the only reference to <code>T</code> then unwrap it. …\nNote: This does not update the schema from the inference …\nGet maximal value that could be hold by this dtype.\nUpsample a <code>DataFrame</code> at a regular frequency.\nUpsample a <code>DataFrame</code> at a regular frequency.\nUse statistics in the parquet to determine if pages can be …\nThe optional validity.\nCreate a <code>DataFrame</code> with the unique <code>values</code> of this <code>Series</code> …\nCount all unique values and create a struct mapping value …\nSafety\nReturns the values of this <code>StructArray</code>.\nReturns an iterator of <code>Box&lt;dyn Array&gt;</code>\nCompute the var of the items in every subarray.\nAggregate all the columns as their variance values.\nCompute the variance of this ChunkedArray/Series.\nVariance of the values of the Series.\nReturns the var value in the array Returns an option …\nGet the variance of the <code>ChunkedArray</code> as a new <code>Series</code> of …\nGet the variance of the Series as a new Series of length 1.\nCompute the hash for all values in the array.\nversion of this file.\nGets the number of <code>Weak</code> pointers to this allocation.\nReturns the ISO week number starting from 1. The return …\nReturns the ISO week number starting from 1. The return …\nReturns the ISO week number starting from 1. The return …\nExtract ISO weekday from underlying NaiveDate …\nExtract ISO weekday from underlying NaiveDateTime …\nReturns the ISO weekday number where monday = 1 and sunday …\nAn optional slice with the same length as the window that …\nStart a <code>when-then-otherwise</code> expression.\nAttach a statement to the corresponding condition.\nAdd another condition to the <code>when-then-otherwise</code> …\nThe length of the window.\nThe length of the window.\nThe right table in the join.\nSet the batch size to use while writing the CSV.\nSet the batch size (number of records to load at one time)\nCache the DataFrame after reading.\nCreate a new, empty schema with capacity\nSets the chunk size used by the parser. This influences …\nSets the chunk size used by the parser. This influences …\nToggle cluster with columns optimization.\nAdd or replace a column, given as an expression, to a …\nInsert a new column in the <code>Schema</code>\nColumns to select/ project\nColumns to select/ project\nAdd or replace multiple columns, given as expressions, to …\nColumns to select/ project\nWhich columns to select.\nAdd or replace multiple columns to a DataFrame, but …\nSet the comment prefix for this instance. Lines starting …\nSets the comment prefix for this instance. Lines starting …\nSet the compression used. Defaults to None.\nSet the compression used. Defaults to None.\nSet the compression used. Defaults to None.\nSet the compression used. Defaults to None.\nSet the compression used. Defaults to <code>Zstd</code>.\nSets the maximum bytes size of a data page. If <code>None</code> will …\nSet the CSV file’s date format.\nSet the CSV file’s datetime format.\nSet the day\nSet the days\nParse floats with a comma as decimal separator.\nSet a dtype.\nOverwrite the schema with the dtypes in this given Schema. …\nOverwrite the dtypes in the schema in the order of the …\nSet  <code>CsvEncoding</code>\nSet the encoding used by the file.\nSet the <code>char</code> used as end of line. The default is <code>b&#39;\\n&#39;</code>.\nSet the character used to indicate an end-of-line (eol).\nSet the extension. Defaults to “.ipc”.\nSet the extension. Defaults to “.ipc”.\nSet the CSV file’s float precision.\nSet <code>milliseconds</code>, <code>microseconds</code>, and <code>nanoseconds</code>\nExpand path given via globbing rules.\nSet whether the CSV file has headers\nSets whether the CSV file has a header row.\nSet <code>hour</code>, <code>minute</code>, and <code>second</code>\nSet <code>hours</code>, <code>minutes</code>, and <code>seconds</code>\nSet the hour\nSet the hours\nReturn a <code>null</code> if an error occurs during parsing.\nContinue with next batch when a ParserError is encountered.\nSet values as <code>Null</code> if parsing fails because of schema …\nSet values as <code>Null</code> if parsing fails because of schema …\nContinue with next batch when a ParserError is encountered.\nSet the number of rows to use when inferring the csv …\nSet the number of rows to use when inferring the json …\nNumber of rows to use for schema inference. Pass None to …\nSet the CSV file’s line terminator.\nReduce memory usage at the expense of performance\nReduce memory consumption at the expense of performance\nCreates a new <code>Field</code> with metadata.\nAttaches a <code>Metadata</code> to <code>ArrowSchema</code>\nSet the microsecond\nSet the microseconds\nSet the milliseconds\nSet the minute\nSet the minutes\nTreat missing fields as null.\nTreat missing fields as null.\nSet the month\nConfigure the row limit.\nStop reading when <code>n</code> rows are read.\nStop reading when <code>n</code> rows are read.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nStop reading at <code>num_rows</code> rows.\nLimits the number of rows to read.\nNumber of threads to use for reading. Defaults to the size …\nSet the nanoseconds\nSet the CSV file’s null value representation.\nSet values that will be interpreted as missing/ null.\nSet values that will be interpreted as missing/null.\nSet allowed optimizations.\nSets the CSV parsing options. See map_parse_options for an …\nSet path of the scanned file. Support glob patterns.\nSet paths of the scanned files. Doesn’t glob patterns.\nToggle predicate pushdown optimization.\nSet the reader’s column projection. This counts from 0, …\nSet the reader’s column projection. This counts from 0, …\nSet the reader’s column projection: the names of the …\nSet the reader’s column projection. This counts from 0, …\nWhich columns to select denoted by their index. The index …\nToggle projection pushdown optimization.\nSet the single byte character used for quoting.\nSet the <code>char</code> used as quote char. The default is <code>b&#39;&quot;&#39;</code>. If …\nSet the character used for field quoting. This is most …\nSet the CSV file’s quoting behavior. See more on …\nRaise an error if CSV is empty (otherwise return an empty …\nWhether to raise an error if the frame is empty. By …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nWhether to makes the columns contiguous in memory.\nTry to estimate the number of rows so that joins can …\nSet the row group size (in number of rows) during writing. …\nConfigure the row index.\nAdd a row index column.\nAdd a row index column.\nAdd a new column at index 0 that counts the rows.\nAdd a row index column.\nAdd a row index column.\nAdd a row index column.\nAdds a row index column.\nField with the same dtype.\nSets the number of rows sampled from the file to determine …\nSet the JSON file’s schema\nSet the CSV file’s schema\nSet the JSON file’s schema\nSet the <code>Schema</code> if already known. This must be exactly the …\nSet the schema to use for CSV file. The length of the …\nModify a schema before we run the lazy scanning.\nOverwrite parts of the inferred schema.\nOverwrites the data types in the schema by column name.\nSet the second\nSet the seconds\nSet the CSV file’s column separator as a byte character.\nSet the CSV file’s column separator as a byte character\nThe character used to separate fields in the CSV file. This\nToggle expression simplification optimization on or off.\nSkip the first <code>n</code> rows during parsing. The header will be …\nNumber of rows to skip before the header row.\nSkip this number of rows after the header location.\nNumber of rows to skip after the header row.\nToggle slice pushdown optimization.\nCompute and write statistic\nRun nodes that are capably of doing so on the streaming …\nSet the CSV file’s time format.\nTruncate lines that are longer than the schema.\nTruncate lines that are longer than the schema.\nAutomatically try to parse dates/datetimes and time. If …\nAutomatically try to parse dates/datetimes and time. If …\nToggle type coercion optimization.\nReturns this array with a new validity.\nSet the weeks\nSet the year\nTurn off all optimizations.\n“xor” operation.\nExtract month from underlying NaiveDate representation. …\nExtract month from underlying NaiveDateTime representation.\nExtract year from underlying NaiveDateTime representation. …\nCreate a new ChunkedArray with values from self where the …\nfunction to apply\nAlso has the input. i.e. avg(“foo”)\nfunction to apply\nfunction arguments\nfunction arguments\nlength is not yet known so we accept negative offsets\noutput dtype of the function\nHelper that combines the groups into a parallel iterator …\nSame helper as <code>_agg_helper_idx</code> but for aggregations that …\nSafety\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>ArrayRef</code> of the same type.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>ArrayRef</code> of the same type.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nApplies a kernel that produces <code>Array</code> types.\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if a binary value contains a literal binary.\nCheck if a binary value ends with the given sequence.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck if a binary value starts with the given sequence.\nSpecialized expressions for Categorical dtypes.\nParsing string values and return a <code>DateChunked</code>\nParsing string values and return a <code>DateChunked</code> Different …\nParsing string values and return a <code>DatetimeChunked</code>.\nParsing string values and return a <code>DatetimeChunked</code> …\nParsing string values and return a <code>TimeChunked</code>\nWhich side windows should be closed.\nExtract day from underlying NaiveDate representation. …\nExtract day from underlying NaiveDateTime representation. …\nExtract the days from a <code>Duration</code>\nOptional parameters for the rolling function\nExtract hour from underlying NaiveDateTime representation. …\nExtract hour from underlying NaiveDateTime representation. …\nExtract the hours from a <code>Duration</code>\nExtract year from underlying NaiveDate representation. …\nExtract year from underlying NaiveDate representation. …\nThis year number might not match the calendar year number.\nExtract the microseconds from a <code>Duration</code>\nExtract the milliseconds from a <code>Duration</code>\nAmount of elements in the window that should be filled …\nExtract minute from underlying NaiveDateTime …\nExtract minute from underlying NaiveDateTime …\nExtract the minutes from a <code>Duration</code>\nExtract month from underlying NaiveDateTime representation.\nExtract month from underlying NaiveDateTime representation.\nExtract second from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nExtract the nanoseconds from a <code>Duration</code>\nReturns the day of year starting from 1.\nReturns the day of year starting from 1.\nExtract month from underlying NaiveDateTime representation.\nExtract quarter from underlying NaiveDateTime …\nApply a rolling max to a Series.\nApply a rolling max to a Series based on another Series.\nApply a rolling mean to a Series.\nApply a rolling mean to a Series based on another Series.\nApply a rolling min to a Series.\nApply a rolling min to a Series based on another Series.\nApply a rolling quantile to a Series.\nApply a rolling quantile to a Series based on another …\nApply a rolling std_dev to a Series.\nApply a rolling std_dev to a Series based on another …\nApply a rolling sum to a Series.\nApply a rolling sum to a Series based on another Series.\nApply a rolling variance to a Series.\nApply a rolling variance to a Series based on another …\nExtract second from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nExtract the seconds from a <code>Duration</code>\nReturns the ISO week number starting from 1. The return …\nReturns the ISO week number starting from 1. The return …\nExtract ISO weekday from underlying NaiveDate …\nExtract ISO weekday from underlying NaiveDateTime …\nThe length of the window.\nExtract month from underlying NaiveDate representation. …\nExtract month from underlying NaiveDateTime representation.\nParsing string values and return a <code>DateChunked</code>\nParsing string values and return a <code>DateChunked</code> Different …\nParsing string values and return a <code>DatetimeChunked</code>.\nParsing string values and return a <code>DatetimeChunked</code> …\nParsing string values and return a <code>TimeChunked</code>\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nOptions to connect to various cloud providers.\nReturns the argument unchanged.\nReturns the argument unchanged.\nParse a configuration from a Hashmap. This is the …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nOptions to connect to various cloud providers.\nA nested list with a fixed size in each row\nThe set of supported logical types in this crate.\nThe time units defined in Arrow.\nOpaque binary data of variable length whose offsets are …\nA binary type that inlines small values and can intern …\nA binary true or false.\n<code>true</code> and <code>false</code>.\nA 32-bit date representing the elapsed time since UNIX …\nA 32-bit date representing the elapsed time since UNIX …\nAn <code>i32</code> representing the elapsed time since UNIX epoch …\nAn <code>i64</code> representing the elapsed time since UNIX epoch …\nA 64-bit date representing the elapsed time since UNIX …\nA 64-bit date representing the elapsed time since UNIX …\nA 128-bit fixed point decimal number.\nFixed point decimal type optional precision and …\nDecimal value with precision and scale precision is the …\nDecimal backed by 256 bits\nA dictionary encoded array (<code>key_type</code>, <code>value_type</code>), where …\nMeasure of elapsed time. This elapsed time is a physical …\nExtension type.\nCharacterizes the name and the <code>DataType</code> of a column.\nOpaque binary data of fixed size. Enum parameter specifies …\nA list of some logical data type with a fixed number of …\nAn 16-bit float\nA 32-bit floating point number.\nA <code>f32</code>\nA 64-bit floating point number.\nA <code>f64</code>\nHashmap: maps the indexes from the global …\nA 16-bit integer number.\nAn <code>i16</code>\nA 32-bit integer number.\nAn <code>i32</code>\nA 64-bit integer number.\nAn <code>i64</code>\nAn 8-bit integer number.\nAn <code>i8</code>\nA “calendar” interval modeling elapsed time that takes …\nOpaque binary data of variable length whose offsets are …\nA list of some logical data type whose offsets are …\nA variable-length UTF-8 encoded string whose offsets are …\nNested type, contains arrays that are filled with one of …\nA nested list with a variable size in each row\nA list of some logical data type whose offsets are …\nUtf8Array: caches the string values and a hash of all …\nMaps a logical type to a chunked array implementation of …\nA nested type that is represented as\nTime in microseconds.\nTime in milliseconds.\nTime in nanoseconds.\nNull type\nCan be used to fmt and implements Any, so can be …\nA generic type that can be used in a <code>Series</code> &amp;’static str …\nThis hashmap uses an IdHasher\nSafety\nTime in seconds.\nA UTF8 encoded string type.\nString data\nAn UTF8 encoded string type.\nA nested <code>ArrowDataType</code> with a given number of <code>Field</code>s.\nThis is logical type <code>StructChunked</code> that dispatches most …\nA 64-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA 32-bit time representing the elapsed time since midnight …\nA 64-bit time representing the elapsed time since midnight …\nA <code>i64</code> representing a timestamp measured in <code>TimeUnit</code> with …\nAn unsigned 16-bit integer number.\nAn <code>u16</code>\nAn unsigned 32-bit integer number.\nAn <code>u32</code>\nAn unsigned 64-bit integer number.\nAn <code>u64</code>\nAn unsigned 8-bit integer number.\nAn <code>u8</code>\nA nested datatype that can represent slots of differing …\nA type unknown to Arrow.\nA variable-length UTF-8 encoded string whose offsets are …\nA string type that inlines small values and can intern …\nGet data type of <code>ChunkedArray</code>.\nGets <code>AnyValue</code> from <code>LogicalType</code>\nSafety\nSafety\nSafety\nSafety\nHashmap: maps the indexes from the global …\nUtf8Array: caches the string values and a hash of all …\nHashmap: maps the indexes from the global …\nUtf8Array: caches the string values and a hash of all …\nEnable the global string cache as long as the object is …\nDisable and clear the global string cache.\nEnable the global string cache.\nCheck whether the global string cache is enabled.\nIf <code>ambiguous</code> is length-1 and not equal to “null”, we …\nSafety\nSafety\nSpecialized expressions for <code>Series</code> with dates/datetimes.\nGet the base offset from UTC.\nChange the underlying <code>TimeUnit</code>. And update the data …\nGet the century of a Date/Datetime\nCombine an existing Date/Datetime with a Time, creating a …\nChange the underlying <code>TimeZone</code> of the <code>Series</code>. This does …\nGet the (local) date of a Date/Datetime.\nGet the (local) datetime of a Datetime.\nGet the month of a Date/Datetime.\nGet the additional offset from UTC currently in effect …\nReturns the argument unchanged.\nGet the hour of a Datetime/Time64.\nCalls <code>U::from(self)</code>.\nGet the iso-year of a Date/Datetime. This may not …\nGet the microsecond of a Time64 (scaled from nanosecs).\nGet the millennium of a Date/Datetime\nGet the millisecond of a Time64 (scaled from nanosecs).\nGet the minute of a Datetime/Time64.\nGet the month of a Date/Datetime.\nGet the nanosecond part of a Time64.\nGet the ordinal_day of a Date/Datetime.\nExtract quarter from underlying NaiveDateTime …\nRound the Datetime/Date range into buckets.\nGet the second of a Datetime/Time64.\nConvert from Date/Time/Datetime into String with the given …\nGet the (local) time of a Date/Datetime/Time.\nReturn the timestamp (UNIX epoch) of a Datetime/Date.\nConvert from Date/Time/Datetime into String with the given …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nTruncate the Datetime/Date range into buckets.\nExtract the week from the underlying Date representation. …\nExtract the ISO week day from the underlying Date …\nChange the underlying <code>TimeUnit</code> of the <code>Series</code>. This does …\nGet the year of a Date/Datetime\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSafety\nSafety\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSafety\nSafety\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nInfer the schema of a CSV file by reading through the …\nCalls <code>U::from(self)</code>.\nSearch through a series of chunks for the first position …\nCalculate the millennium from the underlying NaiveDateTime …\nExtract day from underlying NaiveDateTime representation. …\nExtract hour from underlying NaiveDateTime representation. …\nExtract year from underlying NaiveDateTime representation. …\nCalculate the millennium from the underlying NaiveDateTime …\nExtract minute from underlying NaiveDateTime …\nExtract month from underlying NaiveDateTime representation.\nReturns the number of nanoseconds since the whole non-leap …\nReturns the day of year starting from 1.\nExtract ordinal year from underlying NaiveDateTime …\nExtract quarter from underlying NaiveDateTime …\nExtract second from underlying NaiveDateTime …\nConvert from Time into String with the given format. See …\nConvert date(time) object to timestamp in <code>TimeUnit</code>.\nConvert Time into String with the given format. See chrono …\nReturns the ISO week number starting from 1. The return …\nReturns the ISO weekday number where monday = 1 and sunday …\nExtract year from underlying NaiveDateTime representation. …\nUtility trait to slice concrete arrow arrays whilst …\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nUtility trait to slice concrete arrow arrays whilst …\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nReturn the indices of the bottom k elements.\nUtility trait to slice concrete arrow arrays whilst …\nSort options for multi-series sorting.\nOptions for single series sorting.\nIf true sort in descending order. Default <code>false</code>.\nOrder of the columns. Default all `false``.\nIf true maintain the order of equal elements. Default <code>false</code>…\nWhether maintain the order of equal elements. Default <code>false</code>…\nIf true sort in multiple threads. Default <code>true</code>.\nWhether sort in multiple threads. Default <code>true</code>.\nWhether place null values last. Default <code>false</code>.\nWhether place null values last. Default <code>false</code>.\nSlices this <code>Array</code>.\nSlices the <code>Array</code>.\nConcat with the values from a second StringChunked.\nCheck if strings contain a regex pattern.\nCheck if strings contain a given literal\nCount all successive non-overlapping regex matches.\nCount all successive non-overlapping regex matches.\nExtract the nth capture group from pattern.\nExtract each successive non-overlapping regex match in an …\nExtract each successive non-overlapping regex match in an …\nExtract all capture groups from pattern and return as a …\nReturn the index position of a regular expression …\nReturn the index position of a literal substring in the …\nHorizontally concatenate all strings.")